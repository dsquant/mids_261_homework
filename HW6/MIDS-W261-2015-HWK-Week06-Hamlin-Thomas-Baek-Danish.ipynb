{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#DATASCI W261: Machine Learning at Scale\n",
    "\n",
    "**Nick Hamlin** (nickhamlin@gmail.com)  \n",
    "**Tigi Thomas** (tgthomas@berkeley.edu)  \n",
    "**Rock Baek** (rockb1017@gmail.com)  \n",
    "**Hussein Danish** (husseindanish@gmail.com)  \n",
    "  \n",
    "Time of Submission: 9:23 PM EST, Wednesday, Feb 24, 2016  \n",
    "W261-3, Spring 2016  \n",
    "Week 6 Homework\n",
    "\n",
    "###Submission Notes:\n",
    "- For each problem, we've included a summary of the question as posed in the instructions.  In many cases, we have not included the full text to keep the final submission as uncluttered as possible.  For reference, we've included a link to the original instructions in the \"Useful Reference\" below.\n",
    "- Problem statements are listed in *italics*, while our responses are shown in plain text. \n",
    "- We've included the full output of the mapreduce jobs in our responses so that counter results are shown.  However, these don't always render nicely into PDF form.  In these situations, please reference [the complete rendered notebook on Github](https://github.com/nickhamlin/mids_261_homework/blob/master/HW4/MIDS-W261-2015-HWK-Week06-Hamlin-Thomas-Baek-Danish.ipynb)\n",
    "\n",
    "###Useful References:\n",
    "- **[Original Assignment Instructions](https://www.dropbox.com/sh/5bex8l871t0bg3a/AABXfLW7xv9OUAzY01fMa29za/HW6-Questions.txt?dl=0)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use this to make sure we reload the MrJob code when we make changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 6.0\n",
    "\n",
    "*In mathematics, computer science, economics, or management science what is mathematical optimization? Give an example of a optimization problem that you have worked with directly or that your organization has worked on. Please describe the objective function and the decision variables. Was the project successful (deployed in the real world)? Describe.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##HW6.1 \n",
    "\n",
    "### HW 6.1 Problem Statement\n",
    "Optimization theory: \n",
    "For unconstrained univariate optimization what are the first order necessary Conditions for Optimality (FOC).  What are the second order optimality conditions (SOC)? Give a mathematical defintion. Also in python, plot the univartiate function \n",
    "X^3 -12x^2-6 defined over the real  domain -6 to +6. \n",
    "\n",
    "Also plot its corresponding first and second derivative functions. Eyeballing these graphs, identify candidate optimal points and then classify them as local minimums or maximums. Highlight and label these points in your graphs. Justify your responses using the FOC and SOC.\n",
    "\n",
    "For unconstrained multi-variate optimization what are the first order  Necessary Conditions for Optimality (FOC).  What are the second order optimality conditions (SOC)? Give a mathematical defintion. What is the Hessian matrix in this context?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##HW6.2\n",
    "\n",
    "### HW 6.2 Problem Statement\n",
    "Taking x=1 as the first approximation(xt1) of a root of X^3 + 2x -4 = 0, use the Newton-Raphson method to calculate the second approximation (denoted as xt2) of this root. (Hint the solution is xt2=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##HW6.3 \n",
    "\n",
    "### HW 6.3 Problem Statement\n",
    "Convex optimization \n",
    "What makes an optimization problem convex? What are the first order  Necessary Conditions for Optimality in convex optimization.  What are the second order optimality conditions for convex optimization? Are both necessary to determine the maximum or minimum of candidate optimal solutions?\n",
    "\n",
    "Fill in the BLANKS here:\n",
    "Convex minimization, a subfield of optimization, studies the problem of minimizing BLANK functions over BLANK sets. The BLANK property can make optimization in some sense \"easier\" than the general case - for example, any local minimum must be a global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##HW 6.4\n",
    "The learning objective function for weighted ordinary least squares (WOLS) (aka weight linear regression) is defined as follows:\n",
    "\n",
    "0.5* sumOverTrainingExample i (weight_i * (W * X_i - y_i)^2)\n",
    "\n",
    "Where training set consists of input variables X ( in vector form) and a target variable y, and W is the vector of coefficients for the linear regression model.\n",
    "\n",
    "Derive the gradient for this weighted OLS by hand; showing each step and also explaining each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##HW 6.5\n",
    "Write a MapReduce job in MRJob to do the training at scale of a weighted OLS model using gradient descent.\n",
    "\n",
    "Generate one million datapoints just like in the following notebook:  http://nbviewer.ipython.org/urls/dl.dropbox.com/s/kritdm3mo1daolj/MrJobLinearRegressionGD.ipynb\n",
    "\n",
    "Weight each example as follows: \n",
    "\n",
    "weight(x)= abs(1/x)\n",
    "\n",
    "Sample 1% of the data in MapReduce and use the sampled dataset to train a (weighted if available in SciKit-Learn) linear regression model locally using  SciKit-Learn (http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "\n",
    "Plot the resulting weighted linear regression model versus the original model that you used to generate the data. Comment on your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##HW6.6\n",
    "Clean up notebook for GMM via EM\n",
    "\n",
    "Using the following notebook as a starting point:\n",
    "\n",
    "http://nbviewer.jupyter.org/urls/dl.dropbox.com/s/0t7985e40fovlkw/EM-GMM-MapReduce%20Design%201.ipynb \n",
    "\n",
    "Improve this notebook as follows:\n",
    "-- Add in equations into the notebook (not images of equations) \n",
    "-- Number the equations\n",
    "-- Make sure the equation notation matches the code and the code and comments refer to the equations numbers\n",
    "-- Comment the code\n",
    "-- Rename/Reorganize the code to make it more readable\n",
    "-- Rerun the examples similar graphics (or possibly better graphics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##HW6.7 \n",
    "Implement Bernoulli Mixture Model via EM\n",
    "Implement the EM clustering algorithm to determine Bernoulli Mixture Model for discrete data in MRJob.\n",
    "\n",
    "As a unit test:\n",
    "\n",
    "\n",
    "As a test: use the same dataset from HW 4.5, the Tweet Dataset. \n",
    "Using this data, you will implement a 1000-dimensional EM-based Bernoulli Mixture Model  algorithm in MrJob on the users\n",
    "by their 1000-dimensional word stripes/vectors using K = 4.  Repeat this experiment using your KMeans MRJob implementation fron HW4.\n",
    "Report the rand index score using the class code as ground truth label for both algorithms and comment on your findings.\n",
    "\n",
    "Here is some more information on the Tweet Dataset.\n",
    "\n",
    "Here you will use a different dataset consisting of word-frequency distributions \n",
    "for 1,000 Twitter users. These Twitter users use language in very different ways,\n",
    "and were classified by hand according to the criteria:\n",
    "\n",
    "0: Human, where only basic human-human communication is observed.\n",
    "\n",
    "1: Cyborg, where language is primarily borrowed from other sources\n",
    "(e.g., jobs listings, classifieds postings, advertisements, etc...).\n",
    "\n",
    "2: Robot, where language is formulaically derived from unrelated sources\n",
    "(e.g., weather/seismology, police/fire event logs, etc...).\n",
    "\n",
    "3: Spammer, where language is replicated to high multiplicity\n",
    "(e.g., celebrity obsessions, personal promotion, etc... )\n",
    "\n",
    "Check out the preprints of  recent research,\n",
    "which spawned this dataset:\n",
    "\n",
    "http://arxiv.org/abs/1505.04342\n",
    "http://arxiv.org/abs/1508.01843\n",
    "\n",
    "The main data lie in the accompanying file:\n",
    "\n",
    "topUsers_Apr-Jul_2014_1000-words.txt\n",
    "\n",
    "and are of the form:\n",
    "\n",
    "USERID,CODE,TOTAL,WORD1_COUNT,WORD2_COUNT,...\n",
    ".\n",
    ".\n",
    "\n",
    "where\n",
    "\n",
    "USERID = unique user identifier\n",
    "CODE = 0/1/2/3 class code\n",
    "TOTAL = sum of the word counts\n",
    "\n",
    "Using this data, you will implement a 1000-dimensional K-means algorithm in MrJob on the users\n",
    "by their 1000-dimensional word stripes/vectors using several \n",
    "centroid initializations and values of K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
