{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#DATASCI W261: Machine Learning at Scale\n",
    "\n",
    "**Nick Hamlin** (nickhamlin@gmail.com)  \n",
    "**Tigi Thomas** (tgthomas@berkeley.edu)  \n",
    "**Rock Baek** (rockb1017@gmail.com)  \n",
    "**Hussein Danish** (husseindanish@gmail.com)  \n",
    "  \n",
    "Time of Submission: 10:30 AM EST, Saturday, Feb 27, 2016  \n",
    "W261-3, Spring 2016  \n",
    "Week 7 Homework\n",
    "\n",
    "###Submission Notes:\n",
    "- For each problem, we've included a summary of the question as posed in the instructions.  In many cases, we have not included the full text to keep the final submission as uncluttered as possible.  For reference, we've included a link to the original instructions in the \"Useful Reference\" below.\n",
    "- Some aspects of this notebook don't always render nicely into PDF form.  In these situations, please reference [the complete rendered notebook on Github](https://github.com/nickhamlin/mids_261_homework/blob/master/HW7/MIDS-W261-2015-HWK-Week07-Hamlin-Thomas-Baek-Danish.ipynb)\n",
    "\n",
    "\n",
    "###Useful References:\n",
    "- **[Original Assignment Instructions](https://www.dropbox.com/s/26ejqhkzqdidzwj/HW7-Questions.txt?dl=0)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use this to make sure we reload the MrJob code when we make changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#Render matplotlib charts in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "#Import some modules we know we'll use frequently\n",
    "import numpy as np\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## HW 7.0\n",
    "\n",
    "### HW 7.0 - Problem Statement\n",
    "In this part of your assignment you will develop the base of your code for the week.\n",
    "\n",
    "Write MRJob classes to find shortest path graph distances, \n",
    "as described in the lectures. In addition to finding the distances, \n",
    "your code should also output a distance-minimizing path between the source and target.\n",
    "Work locally for this part of the assignment, and use \n",
    "both of the undirected and directed toy networks.\n",
    "\n",
    "To proof you code's function, run the following jobs\n",
    "\n",
    "- shortest path in the undirected network from node 1 to node 4\n",
    "Solution: 1,5,4 \n",
    "\n",
    "- shortest path in the directed network from node 1 to node 5\n",
    "Solution: 1,2,4,5\n",
    "\n",
    "and report your output---make sure it is correct!\n",
    "\n",
    "### HW 7.0 - MR job definition\n",
    "For brevity, we've combined the initialization step and the main job into a single unit of code.  During the first pass, we check to make sure each node has been properly initialized and, if not, initialize it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing MRbfs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile MRbfs.py\n",
    "from __future__ import division\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.job import MRStep\n",
    "from mrjob.step import MRJobStep\n",
    "import re\n",
    "import ast\n",
    "\n",
    "WORD_RE = re.compile(r\"[\\w']+\")\n",
    " \n",
    "class MRbfs(MRJob):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MRbfs, self).__init__(*args, **kwargs)\n",
    "        self.sN = ''\n",
    "        self.dN = ''\n",
    "        \n",
    "    def mapper_init(self):\n",
    "        #load the begin and End Nodes.. \n",
    "        with open ('start_end.txt', \"rU\") as f:\n",
    "            for line in f:\n",
    "                self.sN, self.dN = line.split(',')\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        line = line.strip('\\n')\n",
    "        data = line.split(\"\\t\")\n",
    "        status = 'U' #everything is unvisited initially\n",
    "        \n",
    "        # This is the first inialization (from original graph file)\n",
    "        # there are only 2 elements, the node and adjacency list\n",
    "        if(len(data) == 2): \n",
    "            nid = data[0]\n",
    "            N = ast.literal_eval(data[1])\n",
    "            \n",
    "            # if our node is the start node , initialize the start\n",
    "            # distance at source = 0.0\n",
    "            if nid == self.sN:\n",
    "                ds = 0.0\n",
    "                status = 'V'\n",
    "            else: \n",
    "                # if this is not the start node, intialize to inf\n",
    "                ds = float(\"inf\")  \n",
    "                \n",
    "            # yeild the root node , dist and graph structure...\n",
    "            # we need this to eventually for next iteration..\n",
    "            yield  nid, (ds, N, status, None)\n",
    "            \n",
    "            # nor each of the nodes in the adjacency list, \n",
    "            # we expand frontier with starting distance.\n",
    "            for m,d in N.iteritems():\n",
    "                #new distance is going to be from root node  + dist              \n",
    "                newdist = d+ds\n",
    "                \n",
    "                #not sure if this is needed really..just \n",
    "                #marking this single node , dist as in the Q.\n",
    "                if newdist < float(\"inf\"):\n",
    "                    status = 'Q'\n",
    "                    \n",
    "                yield m, (newdist, None, status, nid) \n",
    "                \n",
    "        # from Iteration 1 onwards we'll land here...more data items to track\n",
    "        elif len(data) == 5:  \n",
    "            nid = data[0]   #cur Node\n",
    "            dist = data[1]  #cur dist\n",
    "            N = ast.literal_eval(data[2]) # adj list - graph to use for next iter\n",
    "            status = data[3] #status - U, Q, V\n",
    "            visited = data[4] #Pre vist before this node..\n",
    "            \n",
    "            #debug\n",
    "            #print nid, dist, N,status, visited\n",
    "            \n",
    "            # just redo dist, so it is summable ? is this needed ? \n",
    "            dist = float(\"inf\") if dist == 'inf' else float(dist)\n",
    "              \n",
    "            # yeild the root node , dist and graph structure...\n",
    "            # we need this to eventually for next iteration..\n",
    "            yield  nid, (dist, N, status, visited)\n",
    "            \n",
    "            # expand the adjacency list frontier..\n",
    "            if N != None:\n",
    "                for m,d in N.iteritems():\n",
    "                    newdist = d+dist\n",
    "                    if newdist < float(\"inf\") and status <> 'V':\n",
    "                        status = 'Q'\n",
    "                    yield m, (d+dist, None, status, nid)     \n",
    "\n",
    "    #just to debug and see the output coming into the reducer.. \n",
    "    def debug_reducer(self, node, distances):\n",
    "        for dist in distances:\n",
    "            yield node, dist\n",
    "            \n",
    "    def reducer(self, node, distances):\n",
    "        adjList = None\n",
    "        sdist = float(\"inf\")\n",
    "        visited = ''\n",
    "        status = 'U'\n",
    "        for dist in distances:\n",
    "            # for the non-root nodes will have None instead of\n",
    "            # adjacency list\n",
    "            if(dist[1] != None):\n",
    "                adjList = dist[1]           \n",
    "            if dist[0] < sdist:\n",
    "                sdist = dist[0]\n",
    "                visited = dist[3]\n",
    "       \n",
    "        # if we got a distance that is not 'inf' that means\n",
    "        # we vistied the node..mark as V\n",
    "        if sdist < float(\"inf\"):\n",
    "            status = 'V'\n",
    "        yield node, (sdist, adjList, status, visited)\n",
    "        \n",
    "    def steps(self):\n",
    "        return [MRStep( mapper_init=self.mapper_init, \n",
    "                        mapper=self.mapper\n",
    "                        #,reducer=self.debug_reducer\n",
    "                        ,reducer=self.reducer\n",
    "                        #,jobconf = {\n",
    "                        #      'mapred.map.tasks':28,\n",
    "                        #      'mapred.reduce.tasks':28\n",
    "                        #    }\n",
    "                      )\n",
    "                #,MRStep(reducer=self.reducer\n",
    "                #       ,jobconf = {\n",
    "                #               'mapred.map.tasks':10\n",
    "                #              ,'mapred.reduce.tasks':1\n",
    "                #              ,'stream.num.map.output.key.fields':2 \n",
    "                #              ,'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator'\n",
    "                #              ,'mapred.text.key.comparator.options': '-k2,2rn'                             \n",
    "                #            }\n",
    "                #      )\n",
    "                ]\n",
    "if __name__ == '__main__':\n",
    "    MRbfs.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW 7.0 - Test BFS on multiple toy data sets\n",
    "\n",
    "For each of the Data Sets, \n",
    "- create testgraph.txt and start_end.txt\n",
    "- Run smoke test for first iteration\n",
    "- Rum the Driver\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undirected Toy Test Set 1 - create graph file and associated start-end node file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing testgraph.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile testgraph.txt\n",
    "A\t{'B':10, 'D':5}\n",
    "B\t{'C':1, 'D':2}\n",
    "C\t{'E':4}\n",
    "D\t{'B':3, 'C':9, 'E':2}\n",
    "E\t{'A':7, 'C':6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing start_end.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile start_end.txt\n",
    "A,E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directed Toy Test Set 2 - create graph file and associated start-end node file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting testgraph.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile testgraph.txt\n",
    "1\t{'2':1, '6':1}\n",
    "2\t{'1':1, '3':1, '4':1}\n",
    "3\t{'2':1, '4':1}\n",
    "4\t{'2':1, '5':1}\n",
    "5\t{'1':1, '2':1, '4':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting start_end.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile start_end.txt\n",
    "1,5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undirected Toy Test - create graph file and associated start-end node file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting testgraph.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile testgraph.txt\n",
    "1\t{'2': 1,'5': 1}\n",
    "2\t{'1': 1,'3': 1,'4': 1,'5': 1}\n",
    "3\t{'2': 1, '4': 1}\n",
    "4\t{'2': 1,'3': 1,'5': 1}\n",
    "5\t{'1': 1, '2': 1, '4': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting start_end.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile start_end.txt\n",
    "1,4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just a quick test run with first Iteration output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1', [0.0, {'2': 1, '5': 1}, 'V', None])\n",
      "('2', [1.0, {'1': 1, '3': 1, '5': 1, '4': 1}, 'V', '1'])\n",
      "('3', [inf, {'2': 1, '4': 1}, 'U', u''])\n",
      "('4', [inf, {'3': 1, '2': 1, '5': 1}, 'U', u''])\n",
      "('5', [1.0, {'1': 1, '2': 1, '4': 1}, 'V', '1'])\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from MRbfs import MRbfs\n",
    "from __future__ import division\n",
    "\n",
    "mr_job = MRbfs(args=['testgraph.txt', '--file=start_end.txt','--no-strict-protocols'])\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    for line in runner.stream_output():\n",
    "        print mr_job.parse_output_line(line)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now try running the actual job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################################\n",
      "Iteration : 1\n",
      "1\t0.0\t{'2': 1, '5': 1}\tV\tNone\n",
      "2\t1.0\t{'1': 1, '3': 1, '5': 1, '4': 1}\tV\t1\n",
      "3\tinf\t{'2': 1, '4': 1}\tU\t\n",
      "4\tinf\t{'3': 1, '2': 1, '5': 1}\tU\t\n",
      "5\t1.0\t{'1': 1, '2': 1, '4': 1}\tV\t1\n",
      "\n",
      "Prev Total: inf,  Cur Total: inf\n",
      "\n",
      "Shortest Path: []\n",
      "Shortest Distance: inf\n",
      "\n",
      "############################################################\n",
      "Iteration : 2\n",
      "1\t0.0\t{'2': 1, '5': 1}\tV\tNone\n",
      "2\t1.0\t{'1': 1, '3': 1, '5': 1, '4': 1}\tV\t1\n",
      "3\t2.0\t{'2': 1, '4': 1}\tV\t2\n",
      "4\t2.0\t{'3': 1, '2': 1, '5': 1}\tV\t2\n",
      "5\t1.0\t{'1': 1, '2': 1, '4': 1}\tV\t1\n",
      "\n",
      "Prev Total: inf,  Cur Total: 6.0\n",
      "\n",
      "4 2 2.0\n",
      "2 1 1.0\n",
      "1 None 0.0\n",
      "Shortest Path: ['1', '2', '4']\n",
      "Shortest Distance: 2.0\n",
      "\n",
      "############################################################\n",
      "Iteration : 3\n",
      "1\t0.0\t{'2': 1, '5': 1}\tV\tNone\n",
      "2\t1.0\t{'1': 1, '3': 1, '5': 1, '4': 1}\tV\t1\n",
      "3\t2.0\t{'2': 1, '4': 1}\tV\t2\n",
      "4\t2.0\t{'3': 1, '2': 1, '5': 1}\tV\t2\n",
      "5\t1.0\t{'1': 1, '2': 1, '4': 1}\tV\t1\n",
      "\n",
      "Prev Total: 6.0,  Cur Total: 6.0\n",
      "\n",
      "4 2 2.0\n",
      "2 1 1.0\n",
      "1 None 0.0\n",
      "Shortest Path: ['1', '2', '4']\n",
      "Shortest Distance: 2.0\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from __future__ import division\n",
    "from MRbfs import MRbfs\n",
    "\n",
    "mr_job = MRbfs(args=['testgraph.txt', '--file=start_end.txt','--no-strict-protocols'])\n",
    "\n",
    "iterate = 1\n",
    "stop = False\n",
    "\n",
    "# using this to total the overall distance so far.. \n",
    "# another stop condition if we have no new shorted\n",
    "# distances.\n",
    "last_total_dist = float(\"inf\")\n",
    "\n",
    "#Keep our start and end nodes.\n",
    "start_node = ''\n",
    "end_node = ''\n",
    "\n",
    "# we are going to track the distance to the end\n",
    "# node. If we are getting the same distance for the last\n",
    "# few iterations we stop.\n",
    "end_sdist = float(\"inf\")\n",
    "\n",
    "#just for some printng stuff\n",
    "path = {}\n",
    "\n",
    "#Read our Start and End node values.\n",
    "#We keep this to determine stop conditions etc.\n",
    "with open ('start_end.txt', \"rU\") as f:\n",
    "    for line in f:\n",
    "        start_node, end_node = line.split(',')\n",
    "        prev_visited = start_node\n",
    "\n",
    "        \n",
    "# We are iterating till we stop or we hit an interation\n",
    "# count. Count just becuase we want to stop incase there \n",
    "# is a run-off into an inf look.\n",
    "while(not stop and iterate <= 10):\n",
    "    \n",
    "    #kick off our mrjob\n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        \n",
    "        # some pretty print for readibility, debugging etc...\n",
    "        print \"\"\n",
    "        print \"#\" * 60\n",
    "        print \"Iteration : {0}\".format(iterate)\n",
    "        with open(\"testgraph.txt\", 'w+') as f:\n",
    "            \n",
    "            this_iter_total_dist  = 0\n",
    "            for line in runner.stream_output():\n",
    "                nid,distances =  mr_job.parse_output_line(line)\n",
    "                dist,adjlist,status,visited  = distances\n",
    "                \n",
    "                # get the real distance in float so we can total it.. \n",
    "                dist = float(\"inf\") if dist == 'inf' else float(dist)\n",
    "                \n",
    "                # check if for the last node we have hit a non-inf distance\n",
    "                # and there are no new shorter distances.. then stop..\n",
    "                if(nid == end_node and dist < end_sdist):\n",
    "                    end_sdist = dist\n",
    "                elif(nid == end_node and dist == end_sdist and dist != float(\"inf\")):\n",
    "                    #found the shortest distance to the end node.. We can stop..\n",
    "                    stop = True\n",
    "                \n",
    "                # summing the total distance of all nodes in this iteration\n",
    "                # just so we can stop if overall no change in distance..\n",
    "                this_iter_total_dist += dist\n",
    "                print \"{}\\t{}\\t{}\\t{}\\t{}\".format(nid,dist,adjlist,status,visited)\n",
    "                f.write(\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(nid,dist,adjlist,status,visited))\n",
    "                \n",
    "                # add the path to our path collection..\n",
    "                # for printing shortes path etc.. \n",
    "                # node , (visted from, distance)\n",
    "                path[str(nid)] = (str(visited), str(dist))\n",
    "            \n",
    "            print \"\"\n",
    "            print \"Prev Total: {0},  Cur Total: {1}\".format(last_total_dist, this_iter_total_dist)\n",
    "             \n",
    "            # DEBUG the current iteration path list traversal.\n",
    "            #for node, dist in path.iteritems():\n",
    "            #    print node, dist\n",
    "\n",
    "            # just traversing our path from end node, following the visited before chain\n",
    "            # the dict is in the form: node , (visted from, distance)\n",
    "            print \"\"\n",
    "            node = end_node\n",
    "            sdist = path[node][1] \n",
    "            count = 0\n",
    "            spath = []\n",
    "            if( path[node][0] != ''):  \n",
    "                while( node != start_node and node != 'None' and count <= 10):\n",
    "                    print node, path[node][0], path[node][1]\n",
    "                    spath.append(node)\n",
    "                    node = path[node][0]\n",
    "                spath.append(node)\n",
    "                print node, path[node][0], path[node][1]\n",
    "            spath.reverse()    \n",
    "            print \"Shortest Path: {}\".format(spath)\n",
    "            print \"Shortest Distance: {}\".format(sdist)  \n",
    "            \n",
    "            # here we are summing the totals - another stop condition.\n",
    "            if this_iter_total_dist < last_total_dist or this_iter_total_dist == float(\"inf\"):\n",
    "                last_total_dist = this_iter_total_dist\n",
    "            elif this_iter_total_dist == last_total_dist:\n",
    "                last_total_dist = this_iter_total_dist\n",
    "                stop = True\n",
    "                \n",
    "        #Increasea our final block if we get into inf loop.\n",
    "        iterate += 1   \n",
    "            \n",
    "print \"\"\n",
    "print \"Done!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##HW7.1 \n",
    "\n",
    "### HW 7.1 Problem Statement\n",
    "\n",
    "Using MRJob, explore the synonyms network data.\n",
    "Consider plotting the degree distribution (does it follow a power law?),\n",
    "and determine some of the key features, like:\n",
    "\n",
    "number of nodes, \n",
    "number links,\n",
    "or the average degree (i.e., the average number of links per node),\n",
    "etc...\n",
    "\n",
    "As you develop your code, please be sure to run it locally first (though on the whole dataset). \n",
    "Once you have gotten you code to run locally, deploy it on AWS as a systems test\n",
    "in preparation for our next dataset (which will require AWS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mrexplorenltk.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mrexplorenltk.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.job import MRStep\n",
    "import csv\n",
    "import heapq\n",
    "from operator import itemgetter\n",
    "import re\n",
    "import ast\n",
    "\n",
    "class mrexplorenltk(MRJob):\n",
    "    custom_jobconf = None\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(mrexplorenltk, self).__init__(*args, **kwargs)\n",
    "        self.node_count = 0\n",
    "        self.link_count = 0\n",
    "            \n",
    "    def mapper(self, _, line):\n",
    "        line = line.strip('\\n')\n",
    "        data = line.split(\"\\t\")\n",
    "        nid = data[0]\n",
    "        N = ast.literal_eval(data[1])\n",
    "        self.node_count += 1\n",
    "        self.link_count += len(N)\n",
    "     \n",
    "    def mapper_final(self):\n",
    "        yield 'Total Node_Count', self.node_count\n",
    "        yield 'Total Link_Count', self.link_count\n",
    "        \n",
    "    def combiner(self, item, counts):\n",
    "        yield item, sum(counts)\n",
    "        \n",
    "    def reducer(self, item, counts):\n",
    "        yield item, sum(counts)\n",
    "    \n",
    "    def steps(self):\n",
    "        return [MRStep(  mapper=self.mapper\n",
    "                    ,mapper_final = self.mapper_final\n",
    "                    ,combiner=self.combiner\n",
    "                    ,reducer=self.reducer\n",
    "                    #,jobconf = {\n",
    "                    #      'mapred.map.tasks':28,\n",
    "                    #      'mapred.reduce.tasks':28\n",
    "                    #    }\n",
    "                )\n",
    "            #,MRStep(reducer=self.reducer\n",
    "            #       ,jobconf = {\n",
    "            #               'mapred.map.tasks':10\n",
    "            #              ,'mapred.reduce.tasks':1\n",
    "            #              ,'stream.num.map.output.key.fields':2 \n",
    "            #              ,'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator'\n",
    "            #              ,'mapred.text.key.comparator.options': '-k2,2rn'                             \n",
    "            #            }\n",
    "            #      )\n",
    "            ]\n",
    "                \n",
    "if __name__ == '__main__':\n",
    "    mrexplorenltk.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat ./Data/synNet/synNet.txt > synNet.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total Link_Count', 61134)\n",
      "('Total Node_Count', 8271)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from mrexplorenltk import mrexplorenltk\n",
    "\n",
    "mr_job = mrexplorenltk(args=['synNet.txt','--no-strict-protocols'])\n",
    "with mr_job.make_runner() as runner:\n",
    "    runner.run()\n",
    "    count = 0\n",
    "    for line in runner.stream_output():\n",
    "            name,value =  mr_job.parse_output_line(line)\n",
    "            print mr_job.parse_output_line(line)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TODO - Avg etc.. for 7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##HW7.2\n",
    "\n",
    "### HW 7.2 Problem Statement\n",
    "\n",
    "Write (reuse your code from 7.0) an MRJob class to find shortest path graph distances, \n",
    "and apply it to the NLTK synonyms network dataset. \n",
    "\n",
    "Proof your code's function by running the job:\n",
    "\n",
    "- shortest path starting at \"walk\" (index=7827) and ending at \"make\" (index=536),\n",
    "\n",
    "and showing you code's output. Once again, your output should include the path and the distance.\n",
    "\n",
    "As you develop your code, please be sure to run it locally first (though on the whole dataset). \n",
    "Once you have gotten you code to run locally, deploy it on AWS as a systems test\n",
    "in preparation for our next dataset (which will require AWS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy synNet.txt for run , since after the run synNet.txt will change.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat ./Data/synNet/synNet.txt > synNet.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify Start and End Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting start_end.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile start_end.txt\n",
    "7827,536"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Driver (Comment out debug print statements, since we'd have to many items to list..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration : 1\n",
      "\n",
      "Shortest Path: []\n",
      "Shortest Distance: inf\n",
      "\n",
      "Iteration : 2\n",
      "\n",
      "Shortest Path: []\n",
      "Shortest Distance: inf\n",
      "\n",
      "Iteration : 3\n",
      "\n",
      "Shortest Path: ['7827', '1426', '1668', '536']\n",
      "Shortest Distance: 3.0\n",
      "\n",
      "Iteration : 4\n",
      "\n",
      "Shortest Path: ['7827', '1426', '1668', '536']\n",
      "Shortest Distance: 3.0\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from MRbfs import MRbfs\n",
    "from __future__ import division\n",
    "\n",
    "mr_job = MRbfs(args=['synNet.txt', '--file=start_end.txt','--no-strict-protocols'])\n",
    "#mr_job = MRbfs(args=['-r', 'emr', 'synNet.txt', '--file=start_end.txt'])\n",
    "\n",
    "iterate = 1\n",
    "stop = False\n",
    "last_total_dist = float(\"inf\")\n",
    "start_node = ''\n",
    "end_node = ''\n",
    "end_sdist = float(\"inf\")\n",
    "path = {}\n",
    "with open ('start_end.txt', \"rU\") as f:\n",
    "    for line in f:\n",
    "        start_node, end_node = line.split(',')\n",
    "        prev_visited = start_node\n",
    "\n",
    "while(not stop and iterate <= 20):\n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        print \"\"\n",
    "        #print \"#\" * 60\n",
    "        print \"Iteration : {0}\".format(iterate)\n",
    "        with open(\"synNet.txt\", 'w+') as f:\n",
    "            this_iter_total_dist  = 0\n",
    "            for line in runner.stream_output():\n",
    "                nid,distances =  mr_job.parse_output_line(line)\n",
    "                dist,adjlist,status,visited  = distances\n",
    "                if (dist == 'inf'):\n",
    "                    dist = float('inf')\n",
    "                else:\n",
    "                    dist = float(dist)\n",
    "                \n",
    "                if(nid == end_node and dist < end_sdist):\n",
    "                    end_sdist = dist\n",
    "                elif(nid == end_node and dist == end_sdist and dist != float(\"inf\")):\n",
    "                    #found the shortest distance to the end node.. We can stop..\n",
    "                    stop = True\n",
    "                \n",
    "                this_iter_total_dist += dist\n",
    "                #print \"{}\\t{}\\t{}\\t{}\\t{}\".format(nid,dist,adjlist,status,visited)\n",
    "                f.write(\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(nid,dist,adjlist,status,visited))\n",
    "                \n",
    "                path[str(nid)] = (str(visited), str(dist))\n",
    "            \n",
    "            #print \"\"\n",
    "            #print \"Prev Total: {0},  Cur Total: {1}\".format(last_total_dist, this_iter_total_dist)\n",
    "                        \n",
    "            #for node, dist in path.iteritems():\n",
    "            #    print node, dist\n",
    "\n",
    "            print \"\"\n",
    "            node = end_node\n",
    "            sdist = path[node][1] \n",
    "            count = 0\n",
    "            spath = []\n",
    "            if( path[node][0] != ''):  \n",
    "                while( node != start_node and node != 'None' and count <= 10):\n",
    "                    #print node, path[node][0], path[node][1]\n",
    "                    spath.append(node)\n",
    "                    node = path[node][0]\n",
    "                spath.append(node)\n",
    "                #print node, path[node][0], path[node][1]\n",
    "            spath.reverse()    \n",
    "            print \"Shortest Path: {}\".format(spath)\n",
    "            print \"Shortest Distance: {}\".format(sdist)  \n",
    "            \n",
    "            if this_iter_total_dist < last_total_dist or this_iter_total_dist == float(\"inf\"):\n",
    "                last_total_dist = this_iter_total_dist\n",
    "            elif this_iter_total_dist == last_total_dist:\n",
    "                last_total_dist = this_iter_total_dist\n",
    "                stop = 1\n",
    "        #just in case this thing does not stop..\n",
    "        iterate += 1   \n",
    "\n",
    "print \"\"\n",
    "print \"Done!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##HW7.3 \n",
    "\n",
    "### HW 7.3 Problem Statement\n",
    "Using MRJob, explore the Wikipedia network data on the AWS cloud. Reuse your code from HW 7.1---does is scale well? \n",
    "Be cautioned that Wikipedia is a directed network, where links are not symmetric. \n",
    "So, even though a node may be linked to, it will not appear as a primary record itself if it has no out-links. \n",
    "This means that you may have to ADJUST your code (depending on its design). \n",
    "To be sure of your code's functionality in this context, run a systems test on the directed_toy.txt network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##HW 7.4\n",
    "\n",
    "### HW 7.4 - Problem Statement\n",
    "\n",
    "Using MRJob, find shortest path graph distances in the Wikipedia network on the AWS cloud.\n",
    "Reuse your code from 7.2, but once again be warned of Wikipedia being a directed network.\n",
    "To be sure of your code's functionality in this context, run a systems test on the directed_toy.txt network.\n",
    "\n",
    "When running your code on the Wikipedia network, proof its function by running the job:\n",
    "\n",
    "- shortest path from \"Ireland\" (index=6176135) to \"University of California, Berkeley\" (index=13466359),\n",
    "\n",
    "and show your code's output.\n",
    "\n",
    "Once your code is running, find some other shortest paths and report your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##HW 7.5\n",
    "\n",
    "### HW 7.5 Problem Statement\n",
    "Suppose you wanted to find the largest network distance from a single source,\n",
    "i.e., a node that is the furthest (but still reachable) from a single source.\n",
    "\n",
    "How would you implement this task? \n",
    "How is this different from finding the shortest path graph distances?\n",
    "\n",
    "Is this task more difficult to implement than the shortest path distance?\n",
    "\n",
    "As you respond, please comment on program structure, runtimes, iterations, general system requirements, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##End of Submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
