{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#DATASCI W261: Machine Learning at Scale\n",
    "\n",
    "**Nick Hamlin** (nickhamlin@gmail.com)  \n",
    "**Tigi Thomas** (tgthomas@berkeley.edu)  \n",
    "**Rock Baek** (rockb1017@gmail.com)  \n",
    "**Hussein Danish** (husseindanish@gmail.com)  \n",
    "  \n",
    "Time of Submission: 10:30 AM EST, Saturday, Feb 27, 2016  \n",
    "W261-3, Spring 2016  \n",
    "Week 7 Homework\n",
    "\n",
    "###Submission Notes:\n",
    "- For each problem, we've included a summary of the question as posed in the instructions.  In many cases, we have not included the full text to keep the final submission as uncluttered as possible.  For reference, we've included a link to the original instructions in the \"Useful Reference\" below.\n",
    "- Some aspects of this notebook don't always render nicely into PDF form.  In these situations, please reference [the complete rendered notebook on Github](https://github.com/nickhamlin/mids_261_homework/blob/master/HW7/MIDS-W261-2015-HWK-Week07-Hamlin-Thomas-Baek-Danish.ipynb)\n",
    "\n",
    "\n",
    "###Useful References:\n",
    "- **[Original Assignment Instructions](https://www.dropbox.com/s/26ejqhkzqdidzwj/HW7-Questions.txt?dl=0)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use this to make sure we reload the MrJob code when we make changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#Render matplotlib charts in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "#Import some modules we know we'll use frequently\n",
    "import numpy as np\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new scratch bucket mrjob-95d658da5deb24af\n",
      "using s3://mrjob-95d658da5deb24af/tmp/ as our scratch dir on S3\n",
      "Creating persistent job flow to run several jobs in...\n",
      "creating tmp directory /var/folders/rz/drh189k95919thyy3gs3tq400000gn/T/no_script.nicholashamlin.20160310.051638.844663\n",
      "writing master bootstrap script to /var/folders/rz/drh189k95919thyy3gs3tq400000gn/T/no_script.nicholashamlin.20160310.051638.844663/b.py\n",
      "creating S3 bucket 'mrjob-95d658da5deb24af' to use as scratch space\n",
      "Copying non-input files into s3://mrjob-95d658da5deb24af/tmp/no_script.nicholashamlin.20160310.051638.844663/files/\n",
      "Waiting 5.0s for S3 eventual consistency\n",
      "Creating Elastic MapReduce job flow\n",
      "Can't access IAM API, trying default instance profile: EMR_EC2_DefaultRole\n",
      "Can't access IAM API, trying default service role: EMR_DefaultRole\n",
      "Job flow created with ID: j-2MM2A2KMPDLBH\n",
      "j-2MM2A2KMPDLBH\n"
     ]
    }
   ],
   "source": [
    "#Use this line of code to kick off a persistent cluster\n",
    "!python -m mrjob.tools.emr.create_job_flow '--conf-path' 'mrjob.conf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## HW 7.0\n",
    "\n",
    "### HW 7.0 - Problem Statement\n",
    "In this part of your assignment you will develop the base of your code for the week.\n",
    "\n",
    "Write MRJob classes to find shortest path graph distances, \n",
    "as described in the lectures. In addition to finding the distances, \n",
    "your code should also output a distance-minimizing path between the source and target.\n",
    "Work locally for this part of the assignment, and use \n",
    "both of the undirected and directed toy networks.\n",
    "\n",
    "To proof you code's function, run the following jobs\n",
    "\n",
    "- shortest path in the undirected network from node 1 to node 4\n",
    "Solution: 1,5,4 \n",
    "\n",
    "- shortest path in the directed network from node 1 to node 5\n",
    "Solution: 1,2,4,5\n",
    "\n",
    "and report your output---make sure it is correct!\n",
    "\n",
    "### HW 7.0 - MR job definition\n",
    "For brevity, we've combined the initialization step and the main job into a single unit of code.  During the first pass, we check to make sure each node has been properly initialized and, if not, initialize it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting MRbfs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile MRbfs.py\n",
    "from __future__ import division\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.job import MRStep\n",
    "# from mrjob.emr import EMRJobRunner\n",
    "# from boto.s3.key import Key\n",
    "import re\n",
    "import ast\n",
    "\n",
    "WORD_RE = re.compile(r\"[\\w']+\")\n",
    " \n",
    "class MRbfs(MRJob):\n",
    "\n",
    "        \n",
    "    def configure_options(self):\n",
    "        super(MRbfs, self).configure_options()\n",
    "        self.add_passthrough_option('--start', default='1', type=str)\n",
    "        self.add_passthrough_option('--end', default='4', type=str)\n",
    "        self.add_passthrough_option('--statuspath', default='', type=str)\n",
    "        self.add_passthrough_option('--iteration', default='1', type=str)\n",
    "        self.add_passthrough_option('--jobtype', default='local', type=str)\n",
    "\n",
    "        \n",
    "    def mapper(self, node, line):\n",
    "        if self.options.iteration=='1':\n",
    "            line = line.strip('\\n')\n",
    "            data = line.split(\"\\t\")\n",
    "            status = 'U' #everything is unvisited initially\n",
    "\n",
    "            # This is the first inialization (from original graph file)\n",
    "            # there are only 2 elements, the node and adjacency list\n",
    "            if(len(data) == 2): \n",
    "                nid = data[0]\n",
    "                N = ast.literal_eval(data[1])\n",
    "\n",
    "                # if our node is the start node , initialize the start\n",
    "                # distance at source = 0.0\n",
    "                if nid == self.options.start:\n",
    "                    ds = 0.0\n",
    "                    status = 'V'\n",
    "                    path=[nid]\n",
    "                else: \n",
    "                    # if this is not the start node, intialize distance to inf and path to empty list\n",
    "                    ds = float(\"inf\")\n",
    "                    path=[]\n",
    "\n",
    "                # yield the root node , (distance, graph structure, status, \"Visited\", and path (as a list))\n",
    "                # we need this to eventually for next iteration..\n",
    "                yield  nid, (ds, N, status,path)\n",
    "\n",
    "                # nor each of the nodes in the adjacency list, \n",
    "                # we expand frontier with starting distance.\n",
    "                for m,d in N.iteritems():\n",
    "                    #new distance is going to be from root node  + dist              \n",
    "                    newdist = d+ds\n",
    "                    new_path=path[:]\n",
    "                    new_path.append(m)\n",
    "                    #not sure if this is needed really..just \n",
    "                    #marking this single node , dist as in the Q.\n",
    "                    if newdist < float(\"inf\"):\n",
    "                        status = 'Q'\n",
    "\n",
    "                    yield m, (newdist, None, status,new_path)\n",
    "                    #print m, (newdist, None, status,new_path)\n",
    "                \n",
    "        # from Iteration 1 onwards we'll land here...more data items to track\n",
    "        else:# len(data) == 5:\n",
    "            if self.options.jobtype=='local':\n",
    "                inf=float(\"inf\") #THIS IS A TERRIBLE HACKJOB that lets us deal with string/inf eval weirdness\n",
    "                line = line.strip('\\n')\n",
    "                nid,data=eval(line)\n",
    "            \n",
    "            if self.options.jobtype=='emr':\n",
    "                Infinity=float('inf') #SEE HACKJOB ABOVE\n",
    "                line = line.strip('\\n')\n",
    "                nid,data=line.split('\\t')\n",
    "                nid=eval(nid)\n",
    "                data=eval(data)\n",
    "            \n",
    "            \n",
    "            dist=data[0]\n",
    "            N = data[1] # adjacency list - graph to use for next iter\n",
    "            status = data[2] #status - U, Q, V\n",
    "            path=data[3] #list of previously visited nodes\n",
    "            \n",
    "              \n",
    "            #If a node is in the frontier, expand it\n",
    "            if status=='Q':\n",
    "                yield  nid, (dist, N, 'V',path)\n",
    "                #print  nid, (dist, N, 'V',path)\n",
    "                for m,d in N.iteritems():\n",
    "                    newdist=d+dist\n",
    "                    new_path=path[:]\n",
    "                    new_path.append(m)\n",
    "\n",
    "                    yield m, (newdist, None, 'Q', new_path)\n",
    "                    #print m, (newdist, None, 'Q', new_path)\n",
    "            \n",
    "            #If it's not in the frontier, pass it through unchanged\n",
    "            else:        \n",
    "                yield  nid, (dist, N, status,path)\n",
    "                #print  nid, (dist, N, status,path)\n",
    "                    \n",
    "                    \n",
    "    def reducer_init(self):\n",
    "        self.finished=0\n",
    "        self.shortest_path=[]\n",
    "        self.min_dist=0\n",
    "            \n",
    "    def reducer(self, node, distances):\n",
    "        adjList = {} #adjacency list - to be compiled below\n",
    "        sdist = float(\"inf\") #this is the shortest distance we've seen to the node so far\n",
    "        stati = [] #list of all statuses we've encountered for this node\n",
    "        spath=[] #shortest path we've found to the node so far\n",
    "        #node=eval(node)\n",
    "        for dist in distances:\n",
    "            node_dist,list_of_links,temp_status,path=dist[:]\n",
    "\n",
    "            # Extract the original graph structure from the node that has it\n",
    "            if list_of_links:\n",
    "                adjList = list_of_links\n",
    "            \n",
    "            stati.append(temp_status)\n",
    "            \n",
    "            #If we find a record of a visited node, we can move on\n",
    "            if temp_status == 'V':\n",
    "                sdist=node_dist\n",
    "                spath = path\n",
    "                break\n",
    "                       \n",
    "            # If we find a shorter distance to a node, update our knowledge of it\n",
    "            if node_dist < sdist:\n",
    "                sdist = node_dist\n",
    "                spath=path\n",
    "                if node not in spath:\n",
    "                    spath.append(node)\n",
    "            \n",
    "\n",
    "        if 'V' in stati:\n",
    "            status='V'\n",
    "            if node==self.options.end :\n",
    "                self.shortest_path=spath\n",
    "                self.finished=1\n",
    "                self.min_dist=sdist\n",
    "        elif 'Q' in stati:\n",
    "            status='Q'\n",
    "        else:\n",
    "            status='U'\n",
    "            \n",
    "        yield node, (sdist, adjList, status, spath)\n",
    "        #print node, (sdist, adjList, status, spath)        \n",
    "        \n",
    "    def steps(self):\n",
    "        return [MRStep( #mapper_init=self.mapper_init, \n",
    "                        mapper=self.mapper\n",
    "                        ,reducer_init=self.reducer_init\n",
    "                        ,reducer=self.reducer\n",
    "                      )]\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    MRbfs.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW 7.0 - Undirected Toy Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting testgraph.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile testgraph.txt\n",
    "1\t{'2': 1,'5': 1}\n",
    "2\t{'1': 1,'3': 1,'4': 1,'5': 1}\n",
    "3\t{'2': 1, '4': 1}\n",
    "4\t{'2': 1,'3': 1,'5': 1}\n",
    "5\t{'1': 1, '2': 1, '4': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 1\n",
      "Iteration : 2\n",
      "Iteration : 3\n",
      "DONE\n",
      "Shortest path from 1 to 4 is 2 steps long:\n",
      "The path is:  ['1', '2', '4']\n"
     ]
    }
   ],
   "source": [
    "## HW7 - Undirected Toy Example, running locally\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from MRbfs import MRbfs\n",
    "from __future__ import division\n",
    "                                       \n",
    "\n",
    "iterate = 1\n",
    "stop = False\n",
    "last_total_dist = float(\"inf\")\n",
    "start_node = ''\n",
    "end_node = ''\n",
    "end_sdist = float(\"inf\")\n",
    "path = {}\n",
    "\n",
    "\n",
    "#### TEST VERSION #####\n",
    "input_dir_prefix='testgraph'\n",
    "start_node='1'\n",
    "end_node='4'\n",
    "\n",
    "#### NLTK VERSION #####\n",
    "# input_dir_prefix='synNet'\n",
    "# start_node='7827'\n",
    "# end_node='536'\n",
    "\n",
    "\n",
    "#### RUN THE JOBS #####\n",
    "while(not stop and iterate <= 20):\n",
    "    \n",
    "    output_directory=input_dir_prefix+'Output{0}.txt'.format(str(iterate))\n",
    "    if iterate==1:\n",
    "        input_directory=input_dir_prefix+'.txt'\n",
    "    else:\n",
    "        input_directory=input_dir_prefix+'Output{0}.txt'.format(str(iterate-1))\n",
    "\n",
    "    #LOCAL VERSION - IN WHICH WE WRITE RESULTS TO A FILE\n",
    "    mr_job = MRbfs(args=[input_directory, \n",
    "                         #'--file=start_end.txt',\n",
    "                         '--no-strict-protocols',\n",
    "                        '--start',start_node,\n",
    "                        '--end',end_node,\n",
    "                        #'--statuspath',status_path,\n",
    "                        '--iteration',str(iterate)])\n",
    "    \n",
    "    \n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        print \"Iteration : {0}\".format(iterate)\n",
    "        \n",
    "        #Stream output locally\n",
    "        with open(output_directory, 'w+') as f:\n",
    "            for line in runner.stream_output():\n",
    "                nid,distances =  mr_job.parse_output_line(line)\n",
    "                dist,adjlist,status,path  = distances\n",
    "                f.write(str(mr_job.parse_output_line(line))+'\\n')\n",
    "                if nid==end_node and status=='V':\n",
    "                    print \"DONE\"\n",
    "                    print \"Shortest path from {0} to {1} is {2} steps long:\".format(start_node,end_node,str(len(path)-1))\n",
    "                    print \"The path is: \",path\n",
    "                    stop=True \n",
    "                if nid==end_node:\n",
    "                    break\n",
    "\n",
    "        #just in case this thing does not stop..\n",
    "        iterate += 1   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW 7.0 - Directed Toy Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting testgraph.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile testgraph.txt\n",
    "1\t{'2': 1,'5': 1}\n",
    "2\t{'1': 1,'3': 1,'4': 1,'5': 1}\n",
    "3\t{'2': 1, '4': 1}\n",
    "4\t{'2': 1,'3': 1,'5': 1}\n",
    "5\t{'1': 1, '2': 1, '4': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 1\n",
      "Iteration : 2\n",
      "Iteration : 3\n",
      "Iteration : 4\n",
      "DONE\n",
      "Shortest path from 1 to 5 is 3 steps long:\n",
      "The path is:  ['1', '2', '4', '5']\n"
     ]
    }
   ],
   "source": [
    "## HW7 - Directed Toy Example, running locally\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from MRbfs import MRbfs\n",
    "from __future__ import division\n",
    "                                       \n",
    "\n",
    "iterate = 1\n",
    "stop = False\n",
    "last_total_dist = float(\"inf\")\n",
    "start_node = ''\n",
    "end_node = ''\n",
    "end_sdist = float(\"inf\")\n",
    "path = {}\n",
    "\n",
    "\n",
    "#### TEST VERSION #####\n",
    "input_dir_prefix='testgraph'\n",
    "start_node='1'\n",
    "end_node='5'\n",
    "\n",
    "#### NLTK VERSION #####\n",
    "# input_dir_prefix='synNet'\n",
    "# start_node='7827'\n",
    "# end_node='536'\n",
    "\n",
    "\n",
    "#### RUN THE JOBS #####\n",
    "while(not stop and iterate <= 20):\n",
    "    \n",
    "    output_directory=input_dir_prefix+'Output{0}.txt'.format(str(iterate))\n",
    "    if iterate==1:\n",
    "        input_directory=input_dir_prefix+'.txt'\n",
    "    else:\n",
    "        input_directory=input_dir_prefix+'Output{0}.txt'.format(str(iterate-1))\n",
    "\n",
    "    #LOCAL VERSION - IN WHICH WE WRITE RESULTS TO A FILE\n",
    "    mr_job = MRbfs(args=[input_directory, \n",
    "                         #'--file=start_end.txt',\n",
    "                         '--no-strict-protocols',\n",
    "                        '--start',start_node,\n",
    "                        '--end',end_node,\n",
    "                        #'--statuspath',status_path,\n",
    "                        '--iteration',str(iterate)])\n",
    "    \n",
    "    \n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        print \"Iteration : {0}\".format(iterate)\n",
    "        \n",
    "        #Stream output locally\n",
    "        with open(output_directory, 'w+') as f:\n",
    "            for line in runner.stream_output():\n",
    "                nid,distances =  mr_job.parse_output_line(line)\n",
    "                dist,adjlist,status,path  = distances\n",
    "                f.write(str(mr_job.parse_output_line(line))+'\\n')\n",
    "                if nid==end_node and status=='V':\n",
    "                    print \"DONE\"\n",
    "                    print \"Shortest path from {0} to {1} is {2} steps long:\".format(start_node,end_node,str(len(path)-1))\n",
    "                    print \"The path is: \",output\n",
    "                    stop=True \n",
    "                if nid==end_node:\n",
    "                    break\n",
    "\n",
    "        #just in case this thing does not stop..\n",
    "        iterate += 1   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##HW7.1 \n",
    "\n",
    "### HW 7.1 Problem Statement\n",
    "\n",
    "Using MRJob, explore the synonyms network data.\n",
    "Consider plotting the degree distribution (does it follow a power law?),\n",
    "and determine some of the key features, like:\n",
    "\n",
    "number of nodes, \n",
    "number links,\n",
    "or the average degree (i.e., the average number of links per node),\n",
    "etc...\n",
    "\n",
    "As you develop your code, please be sure to run it locally first (though on the whole dataset). \n",
    "Once you have gotten you code to run locally, deploy it on AWS as a systems test\n",
    "in preparation for our next dataset (which will require AWS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mrexplorenltk.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mrexplorenltk.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.job import MRStep\n",
    "import csv\n",
    "import heapq\n",
    "from operator import itemgetter\n",
    "import re\n",
    "import ast\n",
    "\n",
    "class mrexplorenltk(MRJob):\n",
    "    custom_jobconf = None\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(mrexplorenltk, self).__init__(*args, **kwargs)\n",
    "        self.node_count = 0\n",
    "        self.link_count = 0\n",
    "            \n",
    "    def mapper(self, _, line):\n",
    "        line = line.strip('\\n')\n",
    "        data = line.split(\"\\t\")\n",
    "        nid = data[0]\n",
    "        N = ast.literal_eval(data[1])\n",
    "        self.node_count += 1\n",
    "        self.link_count += len(N)\n",
    "     \n",
    "    def mapper_final(self):\n",
    "        yield 'Total Node_Count', self.node_count\n",
    "        yield 'Total Link_Count', self.link_count\n",
    "        \n",
    "    def combiner(self, item, counts):\n",
    "        yield item, sum(counts)\n",
    "        \n",
    "    def reducer(self, item, counts):\n",
    "        yield item, sum(counts)\n",
    "    \n",
    "    def steps(self):\n",
    "        return [MRStep(  mapper=self.mapper\n",
    "                    ,mapper_final = self.mapper_final\n",
    "                    ,combiner=self.combiner\n",
    "                    ,reducer=self.reducer\n",
    "                    #,jobconf = {\n",
    "                    #      'mapred.map.tasks':28,\n",
    "                    #      'mapred.reduce.tasks':28\n",
    "                    #    }\n",
    "                )\n",
    "            #,MRStep(reducer=self.reducer\n",
    "            #       ,jobconf = {\n",
    "            #               'mapred.map.tasks':10\n",
    "            #              ,'mapred.reduce.tasks':1\n",
    "            #              ,'stream.num.map.output.key.fields':2 \n",
    "            #              ,'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator'\n",
    "            #              ,'mapred.text.key.comparator.options': '-k2,2rn'                             \n",
    "            #            }\n",
    "            #      )\n",
    "            ]\n",
    "                \n",
    "if __name__ == '__main__':\n",
    "    mrexplorenltk.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total Link_Count', 61134)\n",
      "('Total Node_Count', 8271)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from mrexplorenltk import mrexplorenltk\n",
    "\n",
    "mr_job = mrexplorenltk(args=['synNet.txt','--no-strict-protocols'])\n",
    "with mr_job.make_runner() as runner:\n",
    "    runner.run()\n",
    "    count = 0\n",
    "    for line in runner.stream_output():\n",
    "            name,value =  mr_job.parse_output_line(line)\n",
    "            print mr_job.parse_output_line(line)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TODO - Avg etc.. for 7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##HW7.2\n",
    "\n",
    "### HW 7.2 Problem Statement\n",
    "\n",
    "Write (reuse your code from 7.0) an MRJob class to find shortest path graph distances, \n",
    "and apply it to the NLTK synonyms network dataset. \n",
    "\n",
    "Proof your code's function by running the job:\n",
    "\n",
    "- shortest path starting at \"walk\" (index=7827) and ending at \"make\" (index=536),\n",
    "\n",
    "and showing you code's output. Once again, your output should include the path and the distance.\n",
    "\n",
    "As you develop your code, please be sure to run it locally first (though on the whole dataset). \n",
    "Once you have gotten you code to run locally, deploy it on AWS as a systems test\n",
    "in preparation for our next dataset (which will require AWS).\n",
    "\n",
    "### HW 7.2 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 1\n",
      "Iteration : 2\n",
      "Iteration : 3\n",
      "Iteration : 4\n",
      "DONE\n",
      "Shortest path from 7827 to 536 is 3 steps long:\n",
      "The path is:  ['7827', '1426', '1668', '536']\n"
     ]
    }
   ],
   "source": [
    "## HW7 - NLTK Example, running locally \n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from MRbfs import MRbfs\n",
    "from __future__ import division\n",
    "                                       \n",
    "\n",
    "iterate = 1\n",
    "stop = False\n",
    "last_total_dist = float(\"inf\")\n",
    "start_node = ''\n",
    "end_node = ''\n",
    "end_sdist = float(\"inf\")\n",
    "path = {}\n",
    "\n",
    "\n",
    "#### TEST VERSION #####\n",
    "# input_dir_prefix='testgraph'\n",
    "# start_node='1'\n",
    "# end_node='5'\n",
    "\n",
    "#### NLTK VERSION #####\n",
    "input_dir_prefix='synNet'\n",
    "start_node='7827'\n",
    "end_node='536'\n",
    "\n",
    "\n",
    "#### RUN THE JOBS #####\n",
    "while(not stop and iterate <= 20):\n",
    "    \n",
    "    output_directory=input_dir_prefix+'Output{0}.txt'.format(str(iterate))\n",
    "    if iterate==1:\n",
    "        input_directory=input_dir_prefix+'.txt'\n",
    "    else:\n",
    "        input_directory=input_dir_prefix+'Output{0}.txt'.format(str(iterate-1))\n",
    "\n",
    "    #LOCAL VERSION - IN WHICH WE WRITE RESULTS TO A FILE\n",
    "    mr_job = MRbfs(args=[input_directory, \n",
    "                         #'--file=start_end.txt',\n",
    "                         '--no-strict-protocols',\n",
    "                        '--start',start_node,\n",
    "                        '--end',end_node,\n",
    "                        #'--statuspath',status_path,\n",
    "                        '--iteration',str(iterate)])\n",
    "    \n",
    "    \n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        print \"Iteration : {0}\".format(iterate)\n",
    "        \n",
    "        #Stream output locally\n",
    "        with open(output_directory, 'w+') as f:\n",
    "            for line in runner.stream_output():\n",
    "                nid,distances =  mr_job.parse_output_line(line)\n",
    "                dist,adjlist,status,path  = distances\n",
    "                f.write(str(mr_job.parse_output_line(line))+'\\n')\n",
    "                if nid==end_node and status=='V':\n",
    "                    print \"DONE\"\n",
    "                    print \"Shortest path from {0} to {1} is {2} steps long:\".format(start_node,end_node,str(len(path)-1))\n",
    "                    print \"The path is: \",path\n",
    "                    stop=True\n",
    "                if nid==end_node:\n",
    "                    break\n",
    "\n",
    "        #just in case this thing does not stop..\n",
    "        iterate += 1   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 1\n",
      "Iteration : 2\n",
      "Iteration : 3\n",
      "Iteration : 4\n",
      "DONE\n",
      "Shortest path from 7827 to 536 is 3 steps long:\n",
      "The path is:  ['7827', '1426', '1688', '536']\n"
     ]
    }
   ],
   "source": [
    "# NLTK example, running in EMR\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from MRbfs import MRbfs\n",
    "from __future__ import division\n",
    "\n",
    "iterate = 1\n",
    "stop = False\n",
    "\n",
    "#PUT CLUSTER HERE!!!!!\n",
    "cluster='j-2MM2A2KMPDLBH'\n",
    "\n",
    "#### TEST VERSION #####\n",
    "# input_dir_prefix='testgraph'\n",
    "# start_node='1'\n",
    "# end_node='5'\n",
    "\n",
    "#### NLTK VERSION #####\n",
    "input_dir_prefix='synNet'\n",
    "start_node='7827'\n",
    "end_node='536'\n",
    "\n",
    "#### RUN THE JOBS #####\n",
    "while(not stop and iterate <= 10):\n",
    "    \n",
    "    #Don't care about this for EMR, since it's defined in the job itself\n",
    "    output_directory=input_dir_prefix+'Output{0}.txt'.format(str(iterate))\n",
    "    if iterate==1:\n",
    "        input_directory='s3://hamlin-mids-261/'+input_dir_prefix+'.txt'\n",
    "    else:\n",
    "        input_directory='s3://hamlin-mids-261/'+input_dir_prefix+'Output{0}/'.format(str(iterate-1))\n",
    "    \n",
    "    #EMR VERSION\n",
    "    mr_job = MRbfs(args=['-r', \n",
    "                         'emr',\n",
    "                         input_directory,\n",
    "                         '--start',start_node,\n",
    "                         '--end',end_node,\n",
    "                         '--no-strict-protocols',\n",
    "                         '--output-dir','s3://hamlin-mids-261/'+input_dir_prefix+'Output{0}'.format(str(iterate)),\n",
    "                         '--no-output',\n",
    "                         '--jobtype','emr',\n",
    "                         '--emr-job-flow-id', cluster,\n",
    "                         '--iteration',str(iterate)\n",
    "                        ])\n",
    "\n",
    " \n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        print \"Iteration : {0}\".format(iterate)\n",
    "        for line in runner.stream_output():\n",
    "            nid,distances =  mr_job.parse_output_line(line)\n",
    "            dist,adjlist,status,path  = distances\n",
    "            #print nid, status, path\n",
    "            if nid==end_node and status=='V':\n",
    "                print \"DONE\"\n",
    "                print \"Shortest path from {0} to {1} is {2} steps long:\".format(start_node,end_node,str(len(path)-1))\n",
    "                print \"The path is: \",path\n",
    "                stop=True\n",
    "            if nid==end_node:\n",
    "                break\n",
    "            \n",
    "        #just in case this thing does not stop..\n",
    "        iterate += 1   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##HW7.3 \n",
    "\n",
    "### HW 7.3 Problem Statement\n",
    "Using MRJob, explore the Wikipedia network data on the AWS cloud. Reuse your code from HW 7.1---does is scale well? \n",
    "Be cautioned that Wikipedia is a directed network, where links are not symmetric. \n",
    "So, even though a node may be linked to, it will not appear as a primary record itself if it has no out-links. \n",
    "This means that you may have to ADJUST your code (depending on its design). \n",
    "To be sure of your code's functionality in this context, run a systems test on the directed_toy.txt network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##HW 7.4\n",
    "\n",
    "### HW 7.4 - Problem Statement\n",
    "\n",
    "Using MRJob, find shortest path graph distances in the Wikipedia network on the AWS cloud.\n",
    "Reuse your code from 7.2, but once again be warned of Wikipedia being a directed network.\n",
    "To be sure of your code's functionality in this context, run a systems test on the directed_toy.txt network.\n",
    "\n",
    "When running your code on the Wikipedia network, proof its function by running the job:\n",
    "\n",
    "- shortest path from \"Ireland\" (index=6176135) to \"University of California, Berkeley\" (index=13466359),\n",
    "\n",
    "and show your code's output.\n",
    "\n",
    "Once your code is running, find some other shortest paths and report your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 1\n",
      "1 V ['1']\n",
      "2 Q ['1', '2']\n",
      "3 U []\n",
      "4 U []\n",
      "5 U []\n",
      "6 Q ['1', '6']\n",
      "\n",
      "Iteration : 2\n",
      "1 V ['1']\n",
      "2 V ['1', '2']\n",
      "3 Q ['1', '2', '3']\n",
      "4 Q ['1', '2', '4']\n",
      "5 U []\n",
      "6 V ['1', '6']\n",
      "\n",
      "Iteration : 3\n",
      "1 V ['1']\n",
      "2 V ['1', '2']\n",
      "3 V ['1', '2', '3']\n",
      "4 Q ['1', '2', '4']\n",
      "5 Q ['1', '2', '4', '5']\n",
      "6 V ['1', '6']\n",
      "\n",
      "Iteration : 4\n",
      "1 V ['1']\n",
      "2 Q ['1', '2']\n",
      "3 V ['1', '2', '3']\n",
      "4 V ['1', '2', '4']\n",
      "5 Q ['1', '2', '4', '5']\n",
      "6 V ['1', '6']\n",
      "\n",
      "Iteration : 5\n",
      "1 V ['1']\n",
      "2 Q ['1', '2']\n",
      "3 Q ['1', '2', '3']\n",
      "4 Q ['1', '2', '4']\n",
      "5 V ['1', '2', '4', '5']\n",
      "DONE\n",
      "Shortest path from 1 to 5 is 3 steps long:\n",
      "The path is:  ['1', '2', '4', '5']\n",
      "6 V ['1', '6']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Directed toy example with FULL output, running on EMR\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from MRbfs import MRbfs\n",
    "from __future__ import division\n",
    "                              \n",
    "iterate = 1\n",
    "stop = False\n",
    "\n",
    "#PUT CLUSTER HERE!!!!!\n",
    "cluster='j-3AH5RMM6FM1X7'\n",
    "\n",
    "#### TEST VERSION #####\n",
    "input_dir_prefix='testgraph'\n",
    "start_node='1'\n",
    "end_node='5'\n",
    "\n",
    "#### NLTK VERSION #####\n",
    "# input_dir_prefix='synNet'\n",
    "# start_node='7827'\n",
    "# end_node='536'\n",
    "\n",
    "#### set status path ####\n",
    "status_path='/Users/nicholashamlin/Documents/Grad School/261 - Machine Learning at Scale/mids_261_homework/HW7/'\n",
    "open(status_path+'status.txt','w').close() #Wipe status file\n",
    "\n",
    "#### RUN THE JOBS #####\n",
    "while(not stop and iterate <= 10):\n",
    "    \n",
    "    if iterate==1:\n",
    "        input_directory='s3://hamlin-mids-261/'+input_dir_prefix+'.txt'\n",
    "    else:\n",
    "        input_directory='s3://hamlin-mids-261/'+input_dir_prefix+'Output{0}/'.format(str(iterate-1))\n",
    "    \n",
    "    #EMR VERSION\n",
    "    mr_job = MRbfs(args=['-r', \n",
    "                         'emr',\n",
    "                         input_directory,\n",
    "                         '--start',start_node,\n",
    "                         '--end',end_node,\n",
    "                         '--no-strict-protocols',\n",
    "                         '--output-dir','s3://hamlin-mids-261/'+input_dir_prefix+'Output{0}'.format(str(iterate)),\n",
    "                         '--no-output',\n",
    "                         '--jobtype','emr',\n",
    "                         '--emr-job-flow-id', cluster,\n",
    "                         '--iteration',str(iterate)\n",
    "                        ])\n",
    "    \n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        print \"Iteration : {0}\".format(iterate)\n",
    "        for line in runner.stream_output():\n",
    "            nid,distances =  mr_job.parse_output_line(line)\n",
    "            dist,adjlist,status,path  = distances\n",
    "            print nid, status, path\n",
    "            if nid==end_node and status=='V':\n",
    "                print \"DONE\"\n",
    "                print \"Shortest path from {0} to {1} is {2} steps long:\".format(start_node,end_node,str(len(path)-1))\n",
    "                print \"The path is: \",path\n",
    "                stop=True \n",
    "        print \"\"\n",
    "            \n",
    "        #just in case this thing does not stop..\n",
    "        iterate += 1   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mrjob.util:hash_object() is deprecated and will be removed in v0.5\n",
      "WARNING:mrjob.util:hash_object() is deprecated and will be removed in v0.5\n",
      "ERROR:boto:403 Forbidden\n",
      "ERROR:boto:<ErrorResponse xmlns=\"https://iam.amazonaws.com/doc/2010-05-08/\">\n",
      "  <Error>\n",
      "    <Type>Sender</Type>\n",
      "    <Code>AccessDenied</Code>\n",
      "    <Message>User: arn:aws:iam::808762113437:user/w261 is not authorized to perform: iam:ListInstanceProfiles on resource: arn:aws:iam::808762113437:instance-profile/</Message>\n",
      "  </Error>\n",
      "  <RequestId>d15db13e-e692-11e5-bef8-c134bc7b96a8</RequestId>\n",
      "</ErrorResponse>\n",
      "\n",
      "WARNING:mrjob.emr:Can't access IAM API, trying default instance profile: EMR_EC2_DefaultRole\n",
      "ERROR:boto:403 Forbidden\n",
      "ERROR:boto:<ErrorResponse xmlns=\"https://iam.amazonaws.com/doc/2010-05-08/\">\n",
      "  <Error>\n",
      "    <Type>Sender</Type>\n",
      "    <Code>AccessDenied</Code>\n",
      "    <Message>User: arn:aws:iam::808762113437:user/w261 is not authorized to perform: iam:ListAttachedRolePolicies on resource: role EMR_DefaultRole</Message>\n",
      "  </Error>\n",
      "  <RequestId>d179c4cf-e692-11e5-a006-c9fd821f768d</RequestId>\n",
      "</ErrorResponse>\n",
      "\n",
      "WARNING:mrjob.emr:Can't access IAM API, trying default service role: EMR_DefaultRole\n",
      "WARNING:mrjob.util:hash_object() is deprecated and will be removed in v0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 1\n",
      "Iteration : 2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mrjob.util:hash_object() is deprecated and will be removed in v0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration : 3\n",
      "DONE\n",
      "Shortest path from 6176135 to 13466359 is 2 steps long:\n",
      "The path is:  ['6176135', '11607791', '13466359']\n"
     ]
    }
   ],
   "source": [
    "# Real-deal Wikipedia data, running in EMR\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from MRbfs import MRbfs\n",
    "from __future__ import division\n",
    "\n",
    "iterate = 1\n",
    "stop = False\n",
    "\n",
    "#PUT CLUSTER HERE!!!!!\n",
    "cluster='j-2MM2A2KMPDLBH'\n",
    "\n",
    "#### TEST VERSION #####\n",
    "# input_dir_prefix='testgraph'\n",
    "# start_node='1'\n",
    "# end_node='5'\n",
    "\n",
    "#### NLTK VERSION #####\n",
    "# input_dir_prefix='synNet'\n",
    "# start_node='7827'\n",
    "# end_node='536'\n",
    "\n",
    "#### WIKIPEDIA VERSION #####\n",
    "input_dir_prefix='wiki'\n",
    "start_node='6176135'\n",
    "end_node='13466359'\n",
    "\n",
    "\n",
    "#### RUN THE JOBS #####\n",
    "while(not stop and iterate <= 10):\n",
    "    \n",
    "    if iterate==1:\n",
    "        input_directory='s3://ucb-mids-mls-networks/wikipedia/all-pages-indexed-out.txt'\n",
    "    else:\n",
    "        input_directory='s3://hamlin-mids-261/'+input_dir_prefix+'Output{0}/'.format(str(iterate-1))\n",
    "    \n",
    "    #EMR VERSION\n",
    "    mr_job = MRbfs(args=['-r', \n",
    "                         'emr',\n",
    "                         input_directory,\n",
    "                         '--start',start_node,\n",
    "                         '--end',end_node,\n",
    "                         '--no-strict-protocols',\n",
    "                         '--output-dir','s3://hamlin-mids-261/'+input_dir_prefix+'Output{0}'.format(str(iterate)),\n",
    "                         '--no-output',\n",
    "                         '--jobtype','emr',\n",
    "                         '--pool-emr-job-flows',\n",
    "                         '--max-hours-idle', '1',\n",
    "                         '--num-ec2-instances', '4',\n",
    "                         '--ec2-instance-type', 'm3.xlarge',\n",
    "                         #'--emr-job-flow-id', cluster,\n",
    "                         '--iteration',str(iterate)\n",
    "                        ])\n",
    "\n",
    " \n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        print \"Iteration : {0}\".format(iterate)\n",
    "        for line in runner.stream_output():\n",
    "            nid,distances =  mr_job.parse_output_line(line)\n",
    "            dist,adjlist,status,path  = distances\n",
    "            #print nid, status, path\n",
    "            if nid==end_node and status=='V':\n",
    "                print \"DONE\"\n",
    "                print \"Shortest path from {0} to {1} is {2} steps long:\".format(start_node,end_node,str(len(path)-1))\n",
    "                print \"The path is: \",path\n",
    "                stop=True\n",
    "            if nid==end_node:\n",
    "                break\n",
    "            \n",
    "        #just in case this thing does not stop..\n",
    "        iterate += 1   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##HW 7.5\n",
    "\n",
    "### HW 7.5 Problem Statement\n",
    "Suppose you wanted to find the largest network distance from a single source,\n",
    "i.e., a node that is the furthest (but still reachable) from a single source.\n",
    "\n",
    "How would you implement this task? \n",
    "How is this different from finding the shortest path graph distances?\n",
    "\n",
    "Is this task more difficult to implement than the shortest path distance?\n",
    "\n",
    "As you respond, please comment on program structure, runtimes, iterations, general system requirements, etc...\n",
    "\n",
    "### HW 7.5 Response\n",
    "We'd find the largest path using a similar, but not exactly the same, approach that we're using here to find the shortest path.  The key difference is that we know in advance that we'll need to thoroughly traverse the entire graph to know that we've found the longest path.  In our shortest path implementation, we stop when we've found the shortest path to the node we're interested in.  This meant that the task isn't necessarily more \"difficult\" from a logical perspective, but it may be more computationally intensive as it would likely require more iterations to arrive at a conclusion.  Since we know we'll need to run several more iterations (and can't take advantage of the \"six-degrees-of-separation\" effect that we can when we look for the shortest path), optimizing both our mapreduce implementation and our cluster infrastructure for rapid turnover is even more important when searching for the longest path.  It shouldn't matter whether we use a depth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##End of Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################################\n",
      "Iteration : 1\n",
      "1\t0.0\t{'2': 1, '5': 1}\tV\tNone\n",
      "2\t1.0\t{'1': 1, '3': 1, '5': 1, '4': 1}\tV\t1\n",
      "3\tinf\t{'2': 1, '4': 1}\tU\t\n",
      "4\tinf\t{'3': 1, '2': 1, '5': 1}\tU\t\n",
      "5\t1.0\t{'1': 1, '2': 1, '4': 1}\tV\t1\n",
      "\n",
      "Prev Total: inf,  Cur Total: inf\n",
      "\n",
      "Shortest Path: []\n",
      "Shortest Distance: inf\n",
      "\n",
      "############################################################\n",
      "Iteration : 2\n",
      "1\t0.0\t{'2': 1, '5': 1}\tV\tNone\n",
      "2\t1.0\t{'1': 1, '3': 1, '5': 1, '4': 1}\tV\t1\n",
      "3\t2.0\t{'2': 1, '4': 1}\tV\t2\n",
      "4\t2.0\t{'3': 1, '2': 1, '5': 1}\tV\t2\n",
      "5\t1.0\t{'1': 1, '2': 1, '4': 1}\tV\t1\n",
      "\n",
      "Prev Total: inf,  Cur Total: 6.0\n",
      "\n",
      "4 2 2.0\n",
      "2 1 1.0\n",
      "1 None 0.0\n",
      "Shortest Path: ['1', '2', '4']\n",
      "Shortest Distance: 2.0\n",
      "\n",
      "############################################################\n",
      "Iteration : 3\n",
      "1\t0.0\t{'2': 1, '5': 1}\tV\tNone\n",
      "2\t1.0\t{'1': 1, '3': 1, '5': 1, '4': 1}\tV\t1\n",
      "3\t2.0\t{'2': 1, '4': 1}\tV\t2\n",
      "4\t2.0\t{'3': 1, '2': 1, '5': 1}\tV\t2\n",
      "5\t1.0\t{'1': 1, '2': 1, '4': 1}\tV\t1\n",
      "\n",
      "Prev Total: 6.0,  Cur Total: 6.0\n",
      "\n",
      "4 2 2.0\n",
      "2 1 1.0\n",
      "1 None 0.0\n",
      "Shortest Path: ['1', '2', '4']\n",
      "Shortest Distance: 2.0\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from __future__ import division\n",
    "from MRbfs import MRbfs\n",
    "\n",
    "mr_job = MRbfs(args=['testgraph.txt', '--file=start_end.txt','--no-strict-protocols'])\n",
    "\n",
    "iterate = 1\n",
    "stop = False\n",
    "\n",
    "# using this to total the overall distance so far.. \n",
    "# another stop condition if we have no new shorted\n",
    "# distances.\n",
    "last_total_dist = float(\"inf\")\n",
    "\n",
    "#Keep our start and end nodes.\n",
    "start_node = ''\n",
    "end_node = ''\n",
    "\n",
    "# we are going to track the distance to the end\n",
    "# node. If we are getting the same distance for the last\n",
    "# few iterations we stop.\n",
    "end_sdist = float(\"inf\")\n",
    "\n",
    "#just for some printng stuff\n",
    "path = {}\n",
    "\n",
    "#Read our Start and End node values.\n",
    "#We keep this to determine stop conditions etc.\n",
    "with open ('start_end.txt', \"rU\") as f:\n",
    "    for line in f:\n",
    "        start_node, end_node = line.split(',')\n",
    "        prev_visited = start_node\n",
    "\n",
    "        \n",
    "# We are iterating till we stop or we hit an interation\n",
    "# count. Count just becuase we want to stop incase there \n",
    "# is a run-off into an inf look.\n",
    "while(not stop and iterate <= 10):\n",
    "    \n",
    "    #kick off our mrjob\n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        \n",
    "        # some pretty print for readibility, debugging etc...\n",
    "        print \"\"\n",
    "        print \"#\" * 60\n",
    "        print \"Iteration : {0}\".format(iterate)\n",
    "        with open(\"testgraph.txt\", 'w+') as f:\n",
    "            \n",
    "            this_iter_total_dist  = 0\n",
    "            for line in runner.stream_output():\n",
    "                nid,distances =  mr_job.parse_output_line(line)\n",
    "                dist,adjlist,status,visited  = distances\n",
    "                \n",
    "                # get the real distance in float so we can total it.. \n",
    "                dist = float(\"inf\") if dist == 'inf' else float(dist)\n",
    "                \n",
    "                # check if for the last node we have hit a non-inf distance\n",
    "                # and there are no new shorter distances.. then stop..\n",
    "                if(nid == end_node and dist < end_sdist):\n",
    "                    end_sdist = dist\n",
    "                elif(nid == end_node and dist == end_sdist and dist != float(\"inf\")):\n",
    "                    #found the shortest distance to the end node.. We can stop..\n",
    "                    stop = True\n",
    "                \n",
    "                # summing the total distance of all nodes in this iteration\n",
    "                # just so we can stop if overall no change in distance..\n",
    "                this_iter_total_dist += dist\n",
    "                print \"{}\\t{}\\t{}\\t{}\\t{}\".format(nid,dist,adjlist,status,visited)\n",
    "                f.write(\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(nid,dist,adjlist,status,visited))\n",
    "                \n",
    "                # add the path to our path collection..\n",
    "                # for printing shortes path etc.. \n",
    "                # node , (visted from, distance)\n",
    "                path[str(nid)] = (str(visited), str(dist))\n",
    "            \n",
    "            print \"\"\n",
    "            print \"Prev Total: {0},  Cur Total: {1}\".format(last_total_dist, this_iter_total_dist)\n",
    "             \n",
    "            # DEBUG the current iteration path list traversal.\n",
    "            #for node, dist in path.iteritems():\n",
    "            #    print node, dist\n",
    "\n",
    "            # just traversing our path from end node, following the visited before chain\n",
    "            # the dict is in the form: node , (visted from, distance)\n",
    "            print \"\"\n",
    "            node = end_node\n",
    "            sdist = path[node][1] \n",
    "            count = 0\n",
    "            spath = []\n",
    "            if( path[node][0] != ''):  \n",
    "                while( node != start_node and node != 'None' and count <= 10):\n",
    "                    print node, path[node][0], path[node][1]\n",
    "                    spath.append(node)\n",
    "                    node = path[node][0]\n",
    "                spath.append(node)\n",
    "                print node, path[node][0], path[node][1]\n",
    "            spath.reverse()    \n",
    "            print \"Shortest Path: {}\".format(spath)\n",
    "            print \"Shortest Distance: {}\".format(sdist)  \n",
    "            \n",
    "            # here we are summing the totals - another stop condition.\n",
    "            if this_iter_total_dist < last_total_dist or this_iter_total_dist == float(\"inf\"):\n",
    "                last_total_dist = this_iter_total_dist\n",
    "            elif this_iter_total_dist == last_total_dist:\n",
    "                last_total_dist = this_iter_total_dist\n",
    "                stop = True\n",
    "                \n",
    "        #Increasea our final block if we get into inf loop.\n",
    "        iterate += 1   \n",
    "            \n",
    "print \"\"\n",
    "print \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1', [0.0, {'2': 1, '5': 1}, 'V', None])\n",
      "('2', [1.0, {'1': 1, '3': 1, '5': 1, '4': 1}, 'V', '1'])\n",
      "('3', [inf, {'2': 1, '4': 1}, 'U', u''])\n",
      "('4', [inf, {'3': 1, '2': 1, '5': 1}, 'U', u''])\n",
      "('5', [1.0, {'1': 1, '2': 1, '4': 1}, 'V', '1'])\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from MRbfs import MRbfs\n",
    "from __future__ import division\n",
    "\n",
    "mr_job = MRbfs(args=['testgraph.txt', '--file=start_end.txt','--no-strict-protocols'])\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    for line in runner.stream_output():\n",
    "        print mr_job.parse_output_line(line)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting MRbfs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile MRbfs.py\n",
    "from __future__ import division\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.job import MRStep\n",
    "from mrjob.step import MRJobStep\n",
    "import re\n",
    "import ast\n",
    "\n",
    "WORD_RE = re.compile(r\"[\\w']+\")\n",
    " \n",
    "class MRbfs(MRJob):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MRbfs, self).__init__(*args, **kwargs)\n",
    "        self.sN = ''\n",
    "        self.dN = ''\n",
    "        \n",
    "    def mapper_init(self):\n",
    "        #load the begin and End Nodes.. \n",
    "        with open ('start_end.txt', \"rU\") as f:\n",
    "            for line in f:\n",
    "                self.sN, self.dN = line.split(',')\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        line = line.strip('\\n')\n",
    "        data = line.split(\"\\t\")\n",
    "        status = 'U' #everything is unvisited initially\n",
    "        \n",
    "        # This is the first inialization (from original graph file)\n",
    "        # there are only 2 elements, the node and adjacency list\n",
    "        if(len(data) == 2): \n",
    "            nid = data[0]\n",
    "            N = ast.literal_eval(data[1])\n",
    "            \n",
    "            # if our node is the start node , initialize the start\n",
    "            # distance at source = 0.0\n",
    "            if nid == self.sN:\n",
    "                ds = 0.0\n",
    "                status = 'V'\n",
    "            else: \n",
    "                # if this is not the start node, intialize to inf\n",
    "                ds = float(\"inf\")  \n",
    "                \n",
    "            # yield the root node , dist and graph structure...\n",
    "            # we need this to eventually for next iteration..\n",
    "            yield  nid, (ds, N, status, None)\n",
    "            \n",
    "            # nor each of the nodes in the adjacency list, \n",
    "            # we expand frontier with starting distance.\n",
    "            for m,d in N.iteritems():\n",
    "                #new distance is going to be from root node  + dist              \n",
    "                newdist = d+ds\n",
    "                \n",
    "                #not sure if this is needed really..just \n",
    "                #marking this single node , dist as in the Q.\n",
    "                if newdist < float(\"inf\"):\n",
    "                    status = 'Q'\n",
    "                    \n",
    "                yield m, (newdist, None, status, nid) \n",
    "                \n",
    "        # from Iteration 1 onwards we'll land here...more data items to track\n",
    "        elif len(data) == 5:  \n",
    "            nid = data[0]   #cur Node\n",
    "            dist = data[1]  #cur dist\n",
    "            N = ast.literal_eval(data[2]) # adj list - graph to use for next iter\n",
    "            status = data[3] #status - U, Q, V\n",
    "            visited = data[4] #Pre vist before this node..\n",
    "            \n",
    "            #debug\n",
    "            #print nid, dist, N,status, visited\n",
    "            \n",
    "            # just redo dist, so it is summable ? is this needed ? \n",
    "            dist = float(\"inf\") if dist == 'inf' else float(dist)\n",
    "              \n",
    "            # yeild the root node , dist and graph structure...\n",
    "            # we need this to eventually for next iteration..\n",
    "            yield  nid, (dist, N, status, visited)\n",
    "            \n",
    "            # expand the adjacency list frontier..\n",
    "            if N != None:\n",
    "                for m,d in N.iteritems():\n",
    "                    newdist = d+dist\n",
    "                    if newdist < float(\"inf\") and status <> 'V':\n",
    "                        status = 'Q'\n",
    "                    yield m, (d+dist, None, status, nid)     \n",
    "\n",
    "    #just to debug and see the output coming into the reducer.. \n",
    "    def debug_reducer(self, node, distances):\n",
    "        for dist in distances:\n",
    "            yield node, dist\n",
    "            \n",
    "    def reducer(self, node, distances):\n",
    "        adjList = None\n",
    "        sdist = float(\"inf\")\n",
    "        visited = ''\n",
    "        status = 'U'\n",
    "        for dist in distances:\n",
    "            # for the non-root nodes will have None instead of\n",
    "            # adjacency list\n",
    "            if(dist[1] != None):\n",
    "                adjList = dist[1]           \n",
    "            if dist[0] < sdist:\n",
    "                sdist = dist[0]\n",
    "                visited = dist[3]\n",
    "       \n",
    "        # if we got a distance that is not 'inf' that means\n",
    "        # we vistied the node..mark as V\n",
    "        if sdist < float(\"inf\"):\n",
    "            status = 'V'\n",
    "        yield node, (sdist, adjList, status, visited)\n",
    "        \n",
    "    def steps(self):\n",
    "        return [MRStep( mapper_init=self.mapper_init, \n",
    "                        mapper=self.mapper\n",
    "                        #,reducer=self.debug_reducer\n",
    "                        ,reducer=self.reducer\n",
    "                        #,jobconf = {\n",
    "                        #      'mapred.map.tasks':28,\n",
    "                        #      'mapred.reduce.tasks':28\n",
    "                        #    }\n",
    "                      )\n",
    "                #,MRStep(reducer=self.reducer\n",
    "                #       ,jobconf = {\n",
    "                #               'mapred.map.tasks':10\n",
    "                #              ,'mapred.reduce.tasks':1\n",
    "                #              ,'stream.num.map.output.key.fields':2 \n",
    "                #              ,'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator'\n",
    "                #              ,'mapred.text.key.comparator.options': '-k2,2rn'                             \n",
    "                #            }\n",
    "                #      )\n",
    "                ]\n",
    "if __name__ == '__main__':\n",
    "    MRbfs.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 1\n",
      "Iteration : 2\n",
      "Iteration : 3\n",
      "Iteration : 4\n",
      "DONE\n",
      "Shortest path from 1 to 5 is 3 steps long:\n",
      "The path is:  ['1', '2', '4', '5']\n"
     ]
    }
   ],
   "source": [
    "## HW7 - Directed Toy Example, running locally\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from MRbfs import MRbfs\n",
    "from __future__ import division\n",
    "                                       \n",
    "\n",
    "iterate = 1\n",
    "stop = False\n",
    "last_total_dist = float(\"inf\")\n",
    "start_node = ''\n",
    "end_node = ''\n",
    "end_sdist = float(\"inf\")\n",
    "path = {}\n",
    "\n",
    "\n",
    "#### TEST VERSION #####\n",
    "input_dir_prefix='testgraph'\n",
    "start_node='1'\n",
    "end_node='5'\n",
    "\n",
    "#### NLTK VERSION #####\n",
    "# input_dir_prefix='synNet'\n",
    "# start_node='7827'\n",
    "# end_node='536'\n",
    "\n",
    "\n",
    "#### RUN THE JOBS #####\n",
    "while(not stop and iterate <= 20):\n",
    "    \n",
    "    output_directory=input_dir_prefix+'Output{0}.txt'.format(str(iterate))\n",
    "    if iterate==1:\n",
    "        input_directory=input_dir_prefix+'.txt'\n",
    "    else:\n",
    "        input_directory=input_dir_prefix+'Output{0}.txt'.format(str(iterate-1))\n",
    "\n",
    "    #LOCAL VERSION - IN WHICH WE WRITE RESULTS TO A FILE\n",
    "    mr_job = MRbfs(args=[input_directory, \n",
    "                         #'--file=start_end.txt',\n",
    "                         '--no-strict-protocols',\n",
    "                        '--start',start_node,\n",
    "                        '--end',end_node,\n",
    "                        #'--statuspath',status_path,\n",
    "                        '--iteration',str(iterate)])\n",
    "    \n",
    "    \n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        print \"Iteration : {0}\".format(iterate)\n",
    "        \n",
    "        #Stream output locally\n",
    "        with open(output_directory, 'w+') as f:\n",
    "            for line in runner.stream_output():\n",
    "                nid,distances =  mr_job.parse_output_line(line)\n",
    "                dist,adjlist,status,path  = distances\n",
    "                f.write(str(mr_job.parse_output_line(line))+'\\n')\n",
    "                if nid==end_node and status=='V':\n",
    "                    print \"DONE\"\n",
    "                    print \"Shortest path from {0} to {1} is {2} steps long:\".format(start_node,end_node,str(len(path)-1))\n",
    "                    print \"The path is: \",output\n",
    "                    stop=True \n",
    "                if nid==end_node:\n",
    "                    break\n",
    "\n",
    "        #just in case this thing does not stop..\n",
    "        iterate += 1   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
