{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#DATASCI W261: Machine Learning at Scale\n",
    "\n",
    "**Nick Hamlin** (nickhamlin@gmail.com)  \n",
    "**Tigi Thomas** (tgthomas@berkeley.edu)  \n",
    "**Rock Baek** (rockb1017@gmail.com)  \n",
    "**Hussein Danish** (husseindanish@gmail.com)  \n",
    "  \n",
    "Time of Submission: 10:30 AM EST, Saturday, Feb 27, 2016  \n",
    "W261-3, Spring 2016  \n",
    "Week 7 Homework\n",
    "\n",
    "###Submission Notes:\n",
    "- For each problem, we've included a summary of the question as posed in the instructions.  In many cases, we have not included the full text to keep the final submission as uncluttered as possible.  For reference, we've included a link to the original instructions in the \"Useful Reference\" below.\n",
    "- Some aspects of this notebook don't always render nicely into PDF form.  In these situations, please reference [the complete rendered notebook on Github](https://github.com/nickhamlin/mids_261_homework/blob/master/HW7/MIDS-W261-2015-HWK-Week07-Hamlin-Thomas-Baek-Danish.ipynb)\n",
    "\n",
    "\n",
    "###Useful References:\n",
    "- **[Original Assignment Instructions](https://www.dropbox.com/s/26ejqhkzqdidzwj/HW7-Questions.txt?dl=0)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Use this to make sure we reload the MrJob code when we make changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#Render matplotlib charts in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "#Import some modules we know we'll use frequently\n",
    "import numpy as np\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 7.0\n",
    "\n",
    "### HW 7.0 - Problem Statement\n",
    "\n",
    "In this part of your assignment you will develop the base of your code for the week.\n",
    "\n",
    "Write MRJob classes to find shortest path graph distances, \n",
    "as described in the lectures. In addition to finding the distances, \n",
    "your code should also output a distance-minimizing path between the source and target.\n",
    "Work locally for this part of the assignment, and use \n",
    "both of the undirected and directed toy networks.\n",
    "\n",
    "To proof you code's function, run the following jobs\n",
    "\n",
    "- shortest path in the undirected network from node 1 to node 4\n",
    "Solution: 1,5,4 \n",
    "\n",
    "- shortest path in the directed network from node 1 to node 5\n",
    "Solution: 1,2,4,5\n",
    "\n",
    "and report your output---make sure it is correct!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t{'2': 1,'5': 1}\r\n",
      "2\t{'1': 1,'3': 1,'4': 1,'5': 1}\r\n",
      "3\t{'2': 1, '4': 1}\r\n",
      "4\t{'2': 1,'3': 1,'5': 1}\r\n",
      "5\t{'1': 1, '2': 1, '4': 1}\r\n"
     ]
    }
   ],
   "source": [
    "!cat undirected_toy.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###HW 7.0 - Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ssp_init.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ssp_init.py\n",
    "import sys\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class SSP_Init(MRJob):        \n",
    "                                                 \n",
    "    def configure_options(self):\n",
    "        \"\"\"\n",
    "        Set up infrastructure to enable us to pass important parameters into the job\n",
    "        when we call it\n",
    "        \"\"\"\n",
    "        super(SSP_Init, self).configure_options()\n",
    "        \n",
    "        #Integer ID of our starting node\n",
    "        self.add_passthrough_option(\n",
    "            '--source', dest='source', default=1, type='int',\n",
    "            help='source: identifier of source node')\n",
    "\n",
    "    \n",
    "    def mapper(self, _, node):\n",
    "        \"\"\"\n",
    "        Broadcast source node and attach statuses to each node\n",
    "        \"\"\"\n",
    "        node_id,links=node.split('\\t')\n",
    "        links=eval(links)\n",
    "        #for unweighted, undirected graph\n",
    "        list_of_links=links.keys() #Probably going to need to modify this to pass weights through as well\n",
    "        if node_id==str(self.options.source):\n",
    "            yield node_id,(list_of_links,0,'Q',[node_id])\n",
    "        else:\n",
    "            yield node_id,(list_of_links,sys.maxint,'U',[]) \n",
    "       \n",
    "    def steps(self):\n",
    "        return [MRStep(\n",
    "                    mapper=self.mapper\n",
    "                      )]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    SSP_Init.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ssp_init import SSP_Init\n",
    "\n",
    "def init_graph(source,data):\n",
    "    mr_job = SSP_Init(args=[data,'--no-strict-protocols','--source',str(source)])\n",
    "    with open('graph.txt','w+') as f:\n",
    "        with mr_job.make_runner() as runner: \n",
    "            runner.run()\n",
    "            for line in runner.stream_output():\n",
    "                f.write(line)\n",
    "                \n",
    "init_graph(1,'directed_toy.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"1\"\t[[\"2\", \"6\"], 0, \"Q\", [\"1\"]]\r\n",
      "\"2\"\t[[\"1\", \"3\", \"4\"], 9223372036854775807, \"U\", []]\r\n",
      "\"3\"\t[[\"2\", \"4\"], 9223372036854775807, \"U\", []]\r\n",
      "\"4\"\t[[\"2\", \"5\"], 9223372036854775807, \"U\", []]\r\n",
      "\"5\"\t[[\"1\", \"2\", \"4\"], 9223372036854775807, \"U\", []]\r\n"
     ]
    }
   ],
   "source": [
    "!cat graph.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###HW 7.0 - Run iterative jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ssp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ssp.py\n",
    "import sys\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class SSP(MRJob):\n",
    "    \n",
    "    def mapper(self, _, node):\n",
    "        \"\"\"\n",
    "        Expand frontier node\n",
    "        \"\"\"\n",
    "        node_id,data=node.split('\\t')\n",
    "        node_id=eval(node_id)\n",
    "        data=eval(data)\n",
    "        list_of_links,dist,status,path=data[:]\n",
    "        if status=='V':\n",
    "            yield node_id,(list_of_links,dist,status,path)\n",
    "            #print node_id,(list_of_links,dist,status)\n",
    "            \n",
    "        if status=='Q':#check if node is in frontier:\n",
    "            #emit the node we visited\n",
    "            yield node_id,(list_of_links,dist,'V',path)\n",
    "            #print node_id,(list_of_links,dist,'V')\n",
    "            \n",
    "            #Emit adjacent nodes\n",
    "            for link in list_of_links:\n",
    "                new_path=path[:]\n",
    "                new_path.append(link)\n",
    "                yield link,(None,dist+1,'Q',new_path) \n",
    "\n",
    "        else:\n",
    "            yield node_id,(list_of_links,sys.maxint,'U',path)\n",
    "            #print node_id,(list_of_links,sys.maxint,'U') \n",
    "        \n",
    "    def reducer(self, node_id, data):  \n",
    "        \"\"\"\n",
    "        Aggregate data for each node and create a consolidated version to pass to the next iteration\n",
    "        \"\"\"\n",
    "        min_dist=sys.maxint\n",
    "        adjacent_nodes=[]\n",
    "        count=0\n",
    "        for i in data:\n",
    "            list_of_links,distance,status,path=i[:]\n",
    "            if list_of_links:\n",
    "                adjacent_nodes=list_of_links\n",
    "            if status in ['Q','V']:\n",
    "                if distance<min_dist:\n",
    "                    min_dist=distance\n",
    "                    if node_id not in path:\n",
    "                        path.append(node_id)\n",
    "            if status=='V':\n",
    "                break\n",
    "            count+=1\n",
    "            #print list_of_links, distance,status\n",
    "            #print i\n",
    "        if count>1:\n",
    "            status='Q'\n",
    "        yield node_id, (adjacent_nodes,min_dist,status,path)\n",
    "        \n",
    "       \n",
    "    def steps(self):\n",
    "        return [MRStep(\n",
    "                    mapper=self.mapper\n",
    "                    ,reducer=self.reducer\n",
    "                      )]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    SSP.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1', [['2', '6'], 0, 'V', ['1']])\n",
      "('2', [['1', '3', '4'], 1, 'Q', ['1', '2']])\n",
      "('3', [['2', '4'], 9223372036854775807, 'U', []])\n",
      "('4', [['2', '5'], 9223372036854775807, 'U', []])\n",
      "('5', [['1', '2', '4'], 9223372036854775807, 'U', []])\n",
      "('6', [[], 1, 'Q', ['1', '6']])\n"
     ]
    }
   ],
   "source": [
    "#SINGLE ITERATION\n",
    "init_graph(1,'directed_toy.txt')\n",
    "from ssp import SSP\n",
    "mr_job = SSP(args=['graph.txt','--no-strict-protocols'])\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    # stream_output: get access of the output \n",
    "    for line in runner.stream_output():\n",
    "        print mr_job.parse_output_line(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now on iteration: 0\n",
      "('1', [['2', '5'], 0, 'V', ['1']])\n",
      "('2', [['1', '3', '5', '4'], 1, 'Q', ['1', '2']])\n",
      "('3', [['2', '4'], 9223372036854775807, 'U', []])\n",
      "('4', [['3', '2', '5'], 9223372036854775807, 'U', []])\n",
      "('5', [['1', '2', '4'], 1, 'Q', ['1', '5']])\n",
      "\n",
      "Now on iteration: 1\n",
      "('1', [['2', '5'], 0, 'V', ['1']])\n",
      "('2', [['1', '3', '5', '4'], 1, 'V', ['1', '2']])\n",
      "('3', [['2', '4'], 2, 'Q', ['1', '2', '3']])\n",
      "('4', [['3', '2', '5'], 2, 'Q', ['1', '5', '4']])\n",
      "('5', [['1', '2', '4'], 1, 'V', ['1', '5']])\n",
      "\n",
      "Now on iteration: 2\n",
      "('1', [['2', '5'], 0, 'V', ['1']])\n",
      "('2', [['1', '3', '5', '4'], 1, 'V', ['1', '2']])\n",
      "('3', [['2', '4'], 2, 'V', ['1', '2', '3']])\n",
      "('4', [['3', '2', '5'], 2, 'V', ['1', '5', '4']])\n",
      "('5', [['1', '2', '4'], 1, 'V', ['1', '5']])\n",
      "\n",
      "Graph has been fully traversed after 3 iterations!\n"
     ]
    }
   ],
   "source": [
    "#MULTIPLE ITERATIONS\n",
    "import os\n",
    "from ssp import SSP\n",
    "mr_job = SSP(args=['graph.txt','--no-strict-protocols'])\n",
    "\n",
    "init_graph(1,'undirected_toy.txt')\n",
    "\n",
    "persist=True\n",
    "count=0\n",
    "while persist:\n",
    "    print \"Now on iteration: \"+str(count)\n",
    "    persist=False\n",
    "    with open('graph_new.txt','w+') as f:\n",
    "        with mr_job.make_runner() as runner: \n",
    "            runner.run()\n",
    "            # stream_output: get access of the output \n",
    "            for line in runner.stream_output():\n",
    "                output=mr_job.parse_output_line(line)\n",
    "                print output\n",
    "                node,data=mr_job.parse_output_line(line)[:]\n",
    "                f.write(line)\n",
    "                #If we encounter any unvisited nodes, continue iterating\n",
    "                if data[2]!='V':\n",
    "                    persist=True\n",
    "                \n",
    "    count+=1\n",
    "    os.rename('graph_new.txt','graph.txt')\n",
    "    print \"\"\n",
    "print \"Graph has been fully traversed after {0} iterations!\".format(str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matches what we'd expect to see based on the slides from class.  We also confirm that the shortest path from node 1 to 4 is [1,5,4]. Now, let's see what we get using the directed graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t{'2': 1, '6': 1}\r\n",
      "2\t{'1': 1, '3': 1, '4': 1}\r\n",
      "3\t{'2': 1, '4': 1}\r\n",
      "4\t{'2': 1, '5': 1}\r\n",
      "5\t{'1': 1, '2': 1, '4': 1}\r\n"
     ]
    }
   ],
   "source": [
    "!cat directed_toy.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t{'2': 1,'5': 1}\r\n",
      "2\t{'1': 1,'3': 1,'4': 1,'5': 1}\r\n",
      "3\t{'2': 1, '4': 1}\r\n",
      "4\t{'2': 1,'3': 1,'5': 1}\r\n",
      "5\t{'1': 1, '2': 1, '4': 1}\r\n"
     ]
    }
   ],
   "source": [
    "!cat undirected_toy.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now on iteration: 0\n",
      "('1', [['2', '6'], 0, 'V', ['1']])\n",
      "('2', [['1', '3', '4'], 1, 'Q', ['1', '2']])\n",
      "('3', [['2', '4'], 9223372036854775807, 'U', []])\n",
      "('4', [['2', '5'], 9223372036854775807, 'U', []])\n",
      "('5', [['1', '2', '4'], 9223372036854775807, 'U', []])\n",
      "('6', [[], 1, 'Q', ['1', '6']])\n",
      "\n",
      "Now on iteration: 1\n",
      "('1', [['2', '6'], 0, 'V', ['1']])\n",
      "('2', [['1', '3', '4'], 1, 'V', ['1', '2']])\n",
      "('3', [['2', '4'], 2, 'Q', ['1', '2', '3']])\n",
      "('4', [['2', '5'], 2, 'Q', ['1', '2', '4']])\n",
      "('5', [['1', '2', '4'], 9223372036854775807, 'U', []])\n",
      "('6', [[], 1, 'V', ['1', '6']])\n",
      "\n",
      "Now on iteration: 2\n",
      "('1', [['2', '6'], 0, 'V', ['1']])\n",
      "('2', [['1', '3', '4'], 1, 'V', ['1', '2']])\n",
      "('3', [['2', '4'], 2, 'V', ['1', '2', '3']])\n",
      "('4', [['2', '5'], 2, 'V', ['1', '2', '4']])\n",
      "('5', [['1', '2', '4'], 3, 'Q', ['1', '2', '4', '5']])\n",
      "('6', [[], 1, 'V', ['1', '6']])\n",
      "\n",
      "Now on iteration: 3\n",
      "('1', [['2', '6'], 0, 'V', ['1']])\n",
      "('2', [['1', '3', '4'], 1, 'V', ['1', '2']])\n",
      "('3', [['2', '4'], 2, 'V', ['1', '2', '3']])\n",
      "('4', [['2', '5'], 2, 'V', ['1', '2', '4']])\n",
      "('5', [['1', '2', '4'], 3, 'V', ['1', '2', '4', '5']])\n",
      "('6', [[], 1, 'V', ['1', '6']])\n",
      "\n",
      "Graph has been fully traversed after 4 iterations!\n"
     ]
    }
   ],
   "source": [
    "#MULTIPLE ITERATIONS\n",
    "import os\n",
    "from ssp import SSP\n",
    "mr_job = SSP(args=['graph.txt','--no-strict-protocols'])\n",
    "\n",
    "init_graph(1,'directed_toy.txt')\n",
    "\n",
    "persist=True\n",
    "count=0\n",
    "while persist:\n",
    "    print \"Now on iteration: \"+str(count)\n",
    "    persist=False\n",
    "    with open('graph_new.txt','w+') as f:\n",
    "        with mr_job.make_runner() as runner: \n",
    "            runner.run()\n",
    "            # stream_output: get access of the output \n",
    "            for line in runner.stream_output():\n",
    "                output=mr_job.parse_output_line(line)\n",
    "                print output\n",
    "                node,data=mr_job.parse_output_line(line)[:]\n",
    "                f.write(line)\n",
    "                #If we encounter any unvisited nodes, continue iterating\n",
    "                if data[2]!='V':\n",
    "                    persist=True\n",
    "                \n",
    "    count+=1\n",
    "    os.rename('graph_new.txt','graph.txt')\n",
    "    print \"\"\n",
    "print \"Graph has been fully traversed after {0} iterations!\".format(str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure enough, we confirm that the shortest path from node 1 to node 5 using the directed graph is [1,2,4,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##HW7.1 \n",
    "\n",
    "### HW 7.1 Problem Statement\n",
    "\n",
    "Using MRJob, explore the synonyms network data.\n",
    "Consider plotting the degree distribution (does it follow a power law?),\n",
    "and determine some of the key features, like:\n",
    "\n",
    "number of nodes, \n",
    "number links,\n",
    "or the average degree (i.e., the average number of links per node),\n",
    "etc...\n",
    "\n",
    "As you develop your code, please be sure to run it locally first (though on the whole dataset). \n",
    "Once you have gotten you code to run locally, deploy it on AWS as a systems test\n",
    "in preparation for our next dataset (which will require AWS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##HW7.2\n",
    "\n",
    "### HW 7.2 Problem Statement\n",
    "\n",
    "Write (reuse your code from 7.0) an MRJob class to find shortest path graph distances, \n",
    "and apply it to the NLTK synonyms network dataset. \n",
    "\n",
    "Proof your code's function by running the job:\n",
    "\n",
    "- shortest path starting at \"walk\" (index=7827) and ending at \"make\" (index=536),\n",
    "\n",
    "and showing you code's output. Once again, your output should include the path and the distance.\n",
    "\n",
    "As you develop your code, please be sure to run it locally first (though on the whole dataset). Once you have gotten you code to run locally, deploy it on AWS as a systems test\n",
    "in preparation for our next dataset (which will require AWS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##HW7.3 \n",
    "\n",
    "### HW 7.3 Problem Statement\n",
    "Using MRJob, explore the Wikipedia network data on the AWS cloud. Reuse your code from HW 7.1---does is scale well? \n",
    "Be cautioned that Wikipedia is a directed network, where links are not symmetric. \n",
    "So, even though a node may be linked to, it will not appear as a primary record itself if it has no out-links. \n",
    "This means that you may have to ADJUST your code (depending on its design). \n",
    "To be sure of your code's functionality in this context, run a systems test on the directed_toy.txt network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##HW 7.4\n",
    "\n",
    "### HW 7.4 - Problem Statement\n",
    "\n",
    "Using MRJob, find shortest path graph distances in the Wikipedia network on the AWS cloud.\n",
    "Reuse your code from 7.2, but once again be warned of Wikipedia being a directed network.\n",
    "To be sure of your code's functionality in this context, run a systems test on the directed_toy.txt network.\n",
    "\n",
    "When running your code on the Wikipedia network, proof its function by running the job:\n",
    "\n",
    "- shortest path from \"Ireland\" (index=6176135) to \"University of California, Berkeley\" (index=13466359),\n",
    "\n",
    "and show your code's output.\n",
    "\n",
    "Once your code is running, find some other shortest paths and report your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##HW 7.5\n",
    "\n",
    "### HW 7.5 Problem Statement\n",
    "Suppose you wanted to find the largest network distance from a single source,\n",
    "i.e., a node that is the furthest (but still reachable) from a single source.\n",
    "\n",
    "How would you implement this task? \n",
    "How is this different from finding the shortest path graph distances?\n",
    "\n",
    "Is this task more difficult to implement than the shortest path distance?\n",
    "\n",
    "As you respond, please comment on program structure, runtimes, iterations, general system requirements, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##End of Submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
